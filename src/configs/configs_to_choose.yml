general:
  n_jobs: 15
  random_seed: 42

preprocessing:

  tokenizer_name:
    #- spacy
    - nltk
    #- gensim

  sentence_vectorizer:
    - fasttext_facebook #
    #- bert-base-uncased
    - endr-bert #
    # - bert-PubMed
    #- bertweet-base
    #- encoder
    #- tfidf
    #- word2vec

  agg_type:
    - mean #
    #- max

  ask_select_novelties:
    #- True
    - False

modeling:
  metric_learner_name:
    #- NCA
    #- LMNN
    #- LFDA
    - siamese
  use_metric_learning:
    - True
    #- False

  siamese_params:
    base_model_output_dim:
      #- 8
      #- 16
      #- 32
      - 64
      - 128
      - 256
      - 512
      - 768
    base_model_layers:
      - 1
      - 2
      - 3
      - 4
      - 5
      - 6
      #- 8
    choosed_dropout:
      - 0.1
      - 0.2
      - 0.4
    batch_size:
      - 128
      - 256
    lr:
      - 0.001
      - 0.01
      - 0.05
      - 0.1
    epochs:
      - 10
      - 20
      - 30
      - 40
      - 50
      #- 100
      #- 500
    patience:
      #- 5
      #- 10
      #- 20
      - 50
      #- 50
      #- 100
      #- 200

    steps_per_epoch:
      #- 50
      #- 35
      #- 10
      #- 70
      #- 140
      - 250

    alpha:
      #- 0.2
      - 0.6
      - 1.0
      - 1.2
      - 1.5

  distance_type:
    #- euclidean
    #- cosine # ТВОЯ НЕЙРОСЕТЬ metric learning ТРЕНИРУЕТСЯ НА КОСИНУСНОЕ РАССТОЯНИЕ И ЕВКЛИДОВО!!
    - minkowski #
    - chebyshev

  model_name:
    #- SVC
    - kNN #
    #- SGD
    #s- LGBM
