{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "afkMAjJfx2Jz"
   },
   "source": [
    "# SIAMESE NETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/kaigorodov/myprojects/MedConcNorm/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.class_balancing import class_sampler\n",
    "from src.support_models.triplet_generator import TripletGenerator\n",
    "from src.support_models.loss_functions import triplet_loss, identity_loss\n",
    "from src.support_models.base_model import base_model\n",
    "from src.support_models.siamese_model_architecture import siamese_model\n",
    "from src.support_models.siamese_metric_learner import SiameseMetricLearner\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8353,
     "status": "ok",
     "timestamp": 1554579362372,
     "user": {
      "displayName": "Eoghan Keany",
      "photoUrl": "",
      "userId": "01744055321449573695"
     },
     "user_tz": -60
    },
    "id": "KzcVM4ZmIBuY",
    "outputId": "7d4bb705-6ab0-4983-ae62-75a3b2d8a292"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/interim/cadec/train.csv')\n",
    "test = pd.read_csv('../data/interim/cadec/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create model embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.utils import tokenize\n",
    "\n",
    "sentences = pd.read_csv('../data/interim/cadec/test.csv')['text'].apply(\n",
    "                lambda x: x.lower().split('<SENT>')).explode().apply(lambda x: list(tokenize(x))).to_list()\n",
    "\n",
    "embed_dim = 100\n",
    "nb_words = 3000\n",
    "\n",
    "ftmodel = FastText(size=embed_dim, window=5, min_count=1)\n",
    "ftmodel.build_vocab(sentences=sentences)\n",
    "ftmodel.train(sentences=sentences, total_examples=len(sentences), epochs=10)\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=nb_words,\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True, split=' ', char_level=False\n",
    ")\n",
    "\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "nb_words = min(nb_words, len(word_index)+1)\n",
    "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= nb_words:\n",
    "        continue\n",
    "    embedding_vector = ftmodel[word]\n",
    "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "word_seq_train = tokenizer.texts_to_sequences(train['term'])\n",
    "word_seq_test = tokenizer.texts_to_sequences(test['term'])\n",
    "\n",
    "max_seq_len = 15\n",
    "\n",
    "X_train = sequence.pad_sequences(word_seq_train, maxlen=max_seq_len)\n",
    "X_test = sequence.pad_sequences(word_seq_test, maxlen=max_seq_len)\n",
    "\n",
    "labels = pd.read_csv('../data/interim/meddra_codes_terms_synonims.csv')\n",
    "labels = labels['CODE']\n",
    "meddra_labels = {v:k for k, v in enumerate(labels.unique())}\n",
    "\n",
    "y_train = train['code'].apply(lambda x: meddra_labels[x]).to_numpy()\n",
    "y_test = test['code'].apply(lambda x: meddra_labels[x]).to_numpy()\n",
    "\n",
    "number_of_classes = labels.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization, Embedding\n",
    "from keras.layers import Bidirectional, LSTM, Dense, Dropout\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Convolution2D, MaxPooling1D\n",
    "\n",
    "\n",
    "def base_model_lstm(embedding_matrix):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Embedding(nb_words, embed_dim, input_length=max_seq_len, \n",
    "                        weights=[embedding_matrix],trainable=False))\n",
    "    model.add(Bidirectional(LSTM(32, return_sequences= True)))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(50, activation='sigmoid'))\n",
    "    model.add(Flatten())\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def siamese_model_lstm(base_model, triple_loss_function, identity_loss_function, learning_rate=0.001):\n",
    "    input_1 = Input(shape=(max_seq_len,), dtype='int32')\n",
    "    input_2 = Input(shape=(max_seq_len,), dtype='int32')\n",
    "    input_3 = Input(shape=(max_seq_len,), dtype='int32')\n",
    "\n",
    "    A = base_model(input_1)\n",
    "    P = base_model(input_2)\n",
    "    N = base_model(input_3)\n",
    "\n",
    "    loss = Lambda(triple_loss_function)([A, P, N])\n",
    "    model = Model(inputs=[input_1, input_2, input_3], outputs=loss)\n",
    "    model.compile(loss=identity_loss_function, optimizer=Adam(learning_rate))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train).shape, np.unique(y_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "sns.histplot(pd.DataFrame({'y_train':y_train})), sns.histplot(pd.DataFrame({'y_test':y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_emb = 768\n",
    "batch_size = 256\n",
    "lr = 1e-3\n",
    "EPOCHS = 100\n",
    "alpha = 0.2 \n",
    "\n",
    "tgen = TripletGenerator()\n",
    "train_generator = tgen.generate_triplets(X_train, y_train, batch_size)\n",
    "test_generator = tgen.generate_triplets(X_test, y_test, batch_size)\n",
    "\n",
    "labels = np.unique(np.concatenate([y_train, y_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# emb_model = base_model(sent_emb)\n",
    "# model = siamese_model(emb_model, sent_emb, triplet_loss, identity_loss, learning_rate=lr)\n",
    "\n",
    "emb_model = base_model_lstm(embedding_matrix)\n",
    "model = siamese_model_lstm(emb_model, triplet_loss, identity_loss, learning_rate=lr)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=15,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator, \n",
    "                              validation_data=test_generator, \n",
    "                              epochs=EPOCHS, \n",
    "                              verbose=1, \n",
    "                              workers=10,\n",
    "                              use_multiprocessing=True,\n",
    "                              steps_per_epoch=20, \n",
    "                              validation_steps=10,\n",
    "                             callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 889,
     "status": "ok",
     "timestamp": 1554498795616,
     "user": {
      "displayName": "Eoghan Keany",
      "photoUrl": "",
      "userId": "01744055321449573695"
     },
     "user_tz": -60
    },
    "id": "68lF6bUhPcD5",
    "outputId": "d1cd4f0d-23b9-4e10-cc9b-723ac203e1cc"
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Training and Validation Losses',size = 20)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UdebpAkhTJ62",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train_trm = emb_model.predict(X_train.reshape(-1, sent_emb, 1))\n",
    "X_test_trm = emb_model.predict(X_test.reshape(-1, sent_emb, 1))\n",
    "X_train.shape, X_train_trm.shape, X_test.shape, X_test_trm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(x, labels, subtitle=None):\n",
    "    palette = np.array(sns.color_palette(\"hls\", 500))\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0,alpha = 0.5, s=40, c=palette[labels.astype(np.int)])\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSNE to use dimensionality reduction to visulaise the resultant embeddings\n",
    "tsne = TSNE()\n",
    "train_tsne = tsne.fit_transform(X_train)\n",
    "print(train_tsne.shape, y_train.shape)\n",
    "scatter(train_tsne, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1373,
     "status": "ok",
     "timestamp": 1554498980246,
     "user": {
      "displayName": "Eoghan Keany",
      "photoUrl": "",
      "userId": "01744055321449573695"
     },
     "user_tz": -60
    },
    "id": "ElmyqDG0o8te",
    "outputId": "abcda512-218a-4a5c-95ca-1872e80a1c48"
   },
   "outputs": [],
   "source": [
    "tsne = TSNE()\n",
    "train_tsne_embeds = tsne.fit_transform(X_train_trm)\n",
    "print(train_tsne_embeds.shape, y_train.shape)\n",
    "scatter(train_tsne_embeds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE()\n",
    "test_tsne = tsne.fit_transform(X_test)\n",
    "print(test_tsne.shape, y_test.shape)\n",
    "scatter(test_tsne, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE()\n",
    "test_tsne_embeds = tsne.fit_transform(X_test_trm)\n",
    "print(test_tsne_embeds.shape, y_test.shape)\n",
    "scatter(test_tsne_embeds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=3)\n",
    "train_to_classify = tsne.fit_transform(X_train_trm)\n",
    "test_to_classify = tsne.fit_transform(X_test_trm)\n",
    "\n",
    "train_to_classify.shape, test_to_classify.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pymedtermino\n",
    "\n",
    "from metric_learn import NCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "generations = 3\n",
    "population_size = 20\n",
    "max_eval_time_mins = 1\n",
    "n_jobs = 10\n",
    "max_iter = 10\n",
    "\n",
    "tpot = TPOTClassifier(generations=generations, \n",
    "                      population_size=population_size,\n",
    "                      verbosity=2, \n",
    "                      random_state=42, \n",
    "                      max_eval_time_mins=max_eval_time_mins, \n",
    "                      n_jobs=n_jobs)\n",
    "\n",
    "tpot.fit(train_tsne_embeds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = tpot.score(train_tsne_embeds, y_train)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = tpot.score(test_tsne_embeds, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score was with low alpha = 0.17439703153988867\n",
    "score was with 0.2 alpha = 0.11873840445269017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([2, 3 , 4, 5, 1, 2, 0 ,1, 2])\n",
    "d = np.array([324, 656, 55453, 2342, 5464, 3244, 23, 545, 23243])\n",
    "\n",
    "y[np.argmin(d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([1, 2, 2, 1, 0 ,0 ,0, 1]*3)\n",
    "d = np.array([2333, 232, 13423, 32423 ,234324, 234, 4545, 23]*3)\n",
    "\n",
    "np.argpartition(d, y.shape[0]-1)[:], y[np.argpartition(d, y.shape[0]-1)[:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3902,
     "status": "ok",
     "timestamp": 1554498988856,
     "user": {
      "displayName": "Eoghan Keany",
      "photoUrl": "",
      "userId": "01744055321449573695"
     },
     "user_tz": -60
    },
    "id": "UrLLhmrg0Vme",
    "outputId": "5a1e047c-b49e-4617-ff24-12c625a8a4f1"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Dropout, Flatten, Convolution2D, MaxPooling2D,ZeroPadding2D\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a Classifier that computes the class of a specific embedding. \n",
    "Classifier_input = Input((10,))\n",
    "Classifier_output = Dense(10, activation='softmax')(Classifier_input)\n",
    "Classifier_model = Model(Classifier_input, Classifier_output)\n",
    "\n",
    "# convert the target labels to onehot encoded vectors.\n",
    "Y_train_onehot = np_utils.to_categorical(y_train, 10)[:sample_size]\n",
    "Y_test_onehot = np_utils.to_categorical(y_test, 10)[:sample_size]\n",
    "\n",
    "Classifier_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "Classifier_model.fit(X_train_trm,Y_train_onehot, validation_data=(X_test_trm,Y_test_onehot),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12823,
     "status": "ok",
     "timestamp": 1553884638254,
     "user": {
      "displayName": "Eoghan Keany",
      "photoUrl": "",
      "userId": "01744055321449573695"
     },
     "user_tz": 0
    },
    "id": "cNMqm62k8AOE",
    "outputId": "ed9f6d94-2327-46cb-b4d7-c21535566f53"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# import io\n",
    "# uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 691,
     "status": "ok",
     "timestamp": 1553884711533,
     "user": {
      "displayName": "Eoghan Keany",
      "photoUrl": "",
      "userId": "01744055321449573695"
     },
     "user_tz": 0
    },
    "id": "h9dUdWPv86e5",
    "outputId": "80f678b3-55f0-401c-f76b-1135b0189a33"
   },
   "outputs": [],
   "source": [
    "# def gini(x):\n",
    "#     # calculates the gini coeffiecent of \n",
    "#     # an array. \n",
    "#     mad = np.abs(np.subtract.outer(x, x)).mean()\n",
    "#     rmad = mad/np.mean(x)\n",
    "#     g = 0.5 * rmad\n",
    "#     return g\n",
    "\n",
    "# def DigitOrNumber(x):\n",
    "#   # Creates an embedding for an image and then calculates the \n",
    "#   # equality of the softmax prediction distribution if it is below a certain threshold\n",
    "#   # then the image will be classified as a digit\n",
    "#   temp = base_model.predict(x)\n",
    "#   temp = Classifier_model.predict(temp)\n",
    "#   if gini(temp) < 0.87:\n",
    "#     print(np.argmax(temp))\n",
    "#   else:\n",
    "#     print('Input is not a Digit')\n",
    "    \n",
    "# # a few examples\n",
    "# x= np.load(io.BytesIO(uploaded['emnist_train_images_3 (1).npy'])) \n",
    "# DigitOrNumber(x[0:1])\n",
    "# DigitOrNumber(x[1:2])\n",
    "# DigitOrNumber(x[2:3])\n",
    "# DigitOrNumber(X_test[20:21])\n",
    "# DigitOrNumber(X_test[500:501])\n",
    "# DigitOrNumber(X_test[1007:1008])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MachinePart1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
