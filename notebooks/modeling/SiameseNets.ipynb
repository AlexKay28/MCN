{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "afkMAjJfx2Jz"
   },
   "source": [
    "# SIAMESE NETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as PathEffects\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/kaigorodov/myprojects/MedConcNorm/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create random configuration\n",
      "create config: 'temp/run_config_default_run_name.yml'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/kaigorodov/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/kaigorodov/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from src.data.class_balancing import class_sampler\n",
    "from src.support_models.triplet_generator import TripletGenerator\n",
    "from src.support_models.loss_functions import triplet_loss, identity_loss\n",
    "from src.support_models.base_model import base_model\n",
    "from src.support_models.siamese_model_architecture import siamese_model\n",
    "from src.support_models.siamese_metric_learner import SiameseMetricLearner\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8353,
     "status": "ok",
     "timestamp": 1554579362372,
     "user": {
      "displayName": "Eoghan Keany",
      "photoUrl": "",
      "userId": "01744055321449573695"
     },
     "user_tz": -60
    },
    "id": "KzcVM4ZmIBuY",
    "outputId": "7d4bb705-6ab0-4983-ae62-75a3b2d8a292"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../data/interim/cadec/train.csv')\n",
    "test = pd.read_csv('../../data/interim/cadec/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sent</th>\n",
       "      <th>text</th>\n",
       "      <th>code</th>\n",
       "      <th>STR</th>\n",
       "      <th>SNMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>back ache</td>\n",
       "      <td>29</td>\n",
       "      <td>38</td>\n",
       "      <td>After the last pill, have been sick to my stom...</td>\n",
       "      <td>Feels like menstrual cramps, back ache, sick t...</td>\n",
       "      <td>10003993</td>\n",
       "      <td>Backache</td>\n",
       "      <td>['Back pain', 'Back pain', 'Back pain', 'Back ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sight gets tired</td>\n",
       "      <td>233</td>\n",
       "      <td>243</td>\n",
       "      <td>At the start of the second week, I accidentall...</td>\n",
       "      <td>- Chest muscle pains.&lt;SENT&gt;- Pins and needles ...</td>\n",
       "      <td>10049755</td>\n",
       "      <td>Eye strain</td>\n",
       "      <td>['Asthenopia', 'Accommodative asthenopia', 'Ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>burning ankles</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>The ball of the foot would feel as if it was i...</td>\n",
       "      <td>Swollen , burning feet and ankles.&lt;SENT&gt;The ba...</td>\n",
       "      <td>10006784</td>\n",
       "      <td>Burning sensation</td>\n",
       "      <td>['Burning sensation', 'Sensation of burning of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>extreme tiredness</td>\n",
       "      <td>42</td>\n",
       "      <td>59</td>\n",
       "      <td>Perhaps the effects were slower because he was...</td>\n",
       "      <td>Husband gradually developed muscle pains, extr...</td>\n",
       "      <td>10016256</td>\n",
       "      <td>Fatigue</td>\n",
       "      <td>['Fatigue', 'Fatigue', 'Fatigue', 'Tiredness',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i felt like I always had the flu</td>\n",
       "      <td>358</td>\n",
       "      <td>390</td>\n",
       "      <td>Do the benefits outweigh the severe side effec...</td>\n",
       "      <td>On 10 mg.&lt;SENT&gt;didnt seem to have any side eff...</td>\n",
       "      <td>10022004</td>\n",
       "      <td>Influenza like illness</td>\n",
       "      <td>['Influenza-like illness', 'Influenza-like ill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3515</th>\n",
       "      <td>extreme pain in neck</td>\n",
       "      <td>150</td>\n",
       "      <td>154</td>\n",
       "      <td>Ice and ibruprofen gel help but only for a sho...</td>\n",
       "      <td>I started taking Lipitor in December 2009 and ...</td>\n",
       "      <td>10033371</td>\n",
       "      <td>Pain</td>\n",
       "      <td>['Pain', 'Pain', 'Pain', 'Pain', 'Pain', 'Pain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3516</th>\n",
       "      <td>severe muscle pain</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>severe muscle pain.</td>\n",
       "      <td>severe muscle pain.&lt;SENT&gt;could not lie on eith...</td>\n",
       "      <td>10033371</td>\n",
       "      <td>Pain</td>\n",
       "      <td>['Pain', 'Pain', 'Pain', 'Pain', 'Pain', 'Pain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3517</th>\n",
       "      <td>twitching mouth</td>\n",
       "      <td>84</td>\n",
       "      <td>99</td>\n",
       "      <td>Symptoms have been gradual over the years with...</td>\n",
       "      <td>headaches, face and scalp tingling, scalp itch...</td>\n",
       "      <td>10045198</td>\n",
       "      <td>Twitching</td>\n",
       "      <td>['Muscle twitch', 'Twitching', 'Twitch', 'Musc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3518</th>\n",
       "      <td>tire very quickly muscles</td>\n",
       "      <td>24</td>\n",
       "      <td>41</td>\n",
       "      <td>Calf muscles (and foot) tire very quickly.</td>\n",
       "      <td>Calf muscles (and foot) tire very quickly.&lt;SEN...</td>\n",
       "      <td>10049565</td>\n",
       "      <td>Muscle fatigue</td>\n",
       "      <td>['Muscle fatigue', 'Muscular fatigue', 'Muscul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3519</th>\n",
       "      <td>heart palpitations</td>\n",
       "      <td>247</td>\n",
       "      <td>265</td>\n",
       "      <td>Had acid reflux-type symptoms for a few days, ...</td>\n",
       "      <td>I took the drug only once, at about 9:00 p.m.&lt;...</td>\n",
       "      <td>10033557</td>\n",
       "      <td>Palpitations</td>\n",
       "      <td>['Palpitations', 'Palpitations', 'Palpitations...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3520 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  term  start  end  \\\n",
       "0                            back ache     29   38   \n",
       "1                     sight gets tired    233  243   \n",
       "2                       burning ankles     27   33   \n",
       "3                    extreme tiredness     42   59   \n",
       "4     i felt like I always had the flu    358  390   \n",
       "...                                ...    ...  ...   \n",
       "3515              extreme pain in neck    150  154   \n",
       "3516                severe muscle pain      0   18   \n",
       "3517                   twitching mouth     84   99   \n",
       "3518         tire very quickly muscles     24   41   \n",
       "3519                heart palpitations    247  265   \n",
       "\n",
       "                                                   sent  \\\n",
       "0     After the last pill, have been sick to my stom...   \n",
       "1     At the start of the second week, I accidentall...   \n",
       "2     The ball of the foot would feel as if it was i...   \n",
       "3     Perhaps the effects were slower because he was...   \n",
       "4     Do the benefits outweigh the severe side effec...   \n",
       "...                                                 ...   \n",
       "3515  Ice and ibruprofen gel help but only for a sho...   \n",
       "3516                                severe muscle pain.   \n",
       "3517  Symptoms have been gradual over the years with...   \n",
       "3518         Calf muscles (and foot) tire very quickly.   \n",
       "3519  Had acid reflux-type symptoms for a few days, ...   \n",
       "\n",
       "                                                   text      code  \\\n",
       "0     Feels like menstrual cramps, back ache, sick t...  10003993   \n",
       "1     - Chest muscle pains.<SENT>- Pins and needles ...  10049755   \n",
       "2     Swollen , burning feet and ankles.<SENT>The ba...  10006784   \n",
       "3     Husband gradually developed muscle pains, extr...  10016256   \n",
       "4     On 10 mg.<SENT>didnt seem to have any side eff...  10022004   \n",
       "...                                                 ...       ...   \n",
       "3515  I started taking Lipitor in December 2009 and ...  10033371   \n",
       "3516  severe muscle pain.<SENT>could not lie on eith...  10033371   \n",
       "3517  headaches, face and scalp tingling, scalp itch...  10045198   \n",
       "3518  Calf muscles (and foot) tire very quickly.<SEN...  10049565   \n",
       "3519  I took the drug only once, at about 9:00 p.m.<...  10033557   \n",
       "\n",
       "                         STR  \\\n",
       "0                   Backache   \n",
       "1                 Eye strain   \n",
       "2          Burning sensation   \n",
       "3                    Fatigue   \n",
       "4     Influenza like illness   \n",
       "...                      ...   \n",
       "3515                    Pain   \n",
       "3516                    Pain   \n",
       "3517               Twitching   \n",
       "3518          Muscle fatigue   \n",
       "3519            Palpitations   \n",
       "\n",
       "                                                   SNMS  \n",
       "0     ['Back pain', 'Back pain', 'Back pain', 'Back ...  \n",
       "1     ['Asthenopia', 'Accommodative asthenopia', 'Ac...  \n",
       "2     ['Burning sensation', 'Sensation of burning of...  \n",
       "3     ['Fatigue', 'Fatigue', 'Fatigue', 'Tiredness',...  \n",
       "4     ['Influenza-like illness', 'Influenza-like ill...  \n",
       "...                                                 ...  \n",
       "3515  ['Pain', 'Pain', 'Pain', 'Pain', 'Pain', 'Pain...  \n",
       "3516  ['Pain', 'Pain', 'Pain', 'Pain', 'Pain', 'Pain...  \n",
       "3517  ['Muscle twitch', 'Twitching', 'Twitch', 'Musc...  \n",
       "3518  ['Muscle fatigue', 'Muscular fatigue', 'Muscul...  \n",
       "3519  ['Palpitations', 'Palpitations', 'Palpitations...  \n",
       "\n",
       "[3520 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create model embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.utils import tokenize\n",
    "\n",
    "sentences = pd.read_csv('../../data/interim/cadec/test.csv')['text'].apply(\n",
    "                lambda x: x.lower().split('<SENT>')).explode().apply(lambda x: list(tokenize(x))).to_list()\n",
    "\n",
    "embed_dim = 100\n",
    "nb_words = 3000\n",
    "\n",
    "ftmodel = FastText(size=embed_dim, window=5, min_count=1)\n",
    "ftmodel.build_vocab(sentences=sentences)\n",
    "ftmodel.train(sentences=sentences, total_examples=len(sentences), epochs=10)\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=nb_words,\n",
    "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "    lower=True, split=' ', char_level=False\n",
    ")\n",
    "\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "nb_words = min(nb_words, len(word_index)+1)\n",
    "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= nb_words:\n",
    "        continue\n",
    "    embedding_vector = ftmodel[word]\n",
    "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "word_seq_train = tokenizer.texts_to_sequences(train['term'])\n",
    "word_seq_test = tokenizer.texts_to_sequences(test['term'])\n",
    "\n",
    "max_seq_len = 15\n",
    "\n",
    "X_train = sequence.pad_sequences(word_seq_train, maxlen=max_seq_len)\n",
    "X_test = sequence.pad_sequences(word_seq_test, maxlen=max_seq_len)\n",
    "\n",
    "labels = pd.read_csv('../../data/interim/meddra_codes_terms_synonims.csv')\n",
    "labels = labels['CODE']\n",
    "meddra_labels = {v:k for k, v in enumerate(labels.unique())}\n",
    "\n",
    "y_train = train['code'].apply(lambda x: meddra_labels[x]).to_numpy()\n",
    "y_test = test['code'].apply(lambda x: meddra_labels[x]).to_numpy()\n",
    "\n",
    "number_of_classes = labels.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    0,   32,  467],\n",
       "       [   0,    0,    0, ..., 1182, 1224,  282],\n",
       "       [   0,    0,    0, ...,    0,  409,  406],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    0,  578, 1035],\n",
       "       [   0,    0,    0, ...,   60, 1032,  160],\n",
       "       [   0,    0,    0, ...,    0,  153, 2139]], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import BatchNormalization, Embedding\n",
    "from keras.layers import Bidirectional, LSTM, Dense, Dropout\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Convolution2D, MaxPooling1D\n",
    "\n",
    "\n",
    "def base_model_lstm(embedding_matrix):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Embedding(nb_words, embed_dim, input_length=max_seq_len, \n",
    "                        weights=[embedding_matrix],trainable=False))\n",
    "    model.add(Bidirectional(LSTM(32, return_sequences= True)))\n",
    "    model.add(Dense(32,activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(50, activation='sigmoid'))\n",
    "    model.add(Flatten())\n",
    "    #model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def siamese_model_lstm(base_model, triple_loss_function, identity_loss_function, learning_rate=0.001):\n",
    "    input_1 = Input(shape=(max_seq_len,), dtype='int32')\n",
    "    input_2 = Input(shape=(max_seq_len,), dtype='int32')\n",
    "    input_3 = Input(shape=(max_seq_len,), dtype='int32')\n",
    "\n",
    "    A = base_model(input_1)\n",
    "    P = base_model(input_2)\n",
    "    N = base_model(input_3)\n",
    "\n",
    "    loss = Lambda(triple_loss_function)([A, P, N])\n",
    "    model = Model(inputs=[input_1, input_2, input_3], outputs=loss)\n",
    "    model.compile(loss=identity_loss_function, optimizer=Adam(learning_rate))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train).shape, np.unique(y_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "sns.histplot(pd.DataFrame({'y_train':y_train})), sns.histplot(pd.DataFrame({'y_test':y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_emb = 768\n",
    "batch_size = 256\n",
    "lr = 1e-3\n",
    "EPOCHS = 100\n",
    "alpha = 0.2 \n",
    "\n",
    "tgen = TripletGenerator()\n",
    "train_generator = tgen.generate_triplets(X_train, y_train, batch_size)\n",
    "test_generator = tgen.generate_triplets(X_test, y_test, batch_size)\n",
    "\n",
    "labels = np.unique(np.concatenate([y_train, y_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# emb_model = base_model(sent_emb)\n",
    "# model = siamese_model(emb_model, sent_emb, triplet_loss, identity_loss, learning_rate=lr)\n",
    "\n",
    "emb_model = base_model_lstm(embedding_matrix)\n",
    "model = siamese_model_lstm(emb_model, triplet_loss, identity_loss, learning_rate=lr)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=15,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator, \n",
    "                              validation_data=test_generator, \n",
    "                              epochs=EPOCHS, \n",
    "                              verbose=1, \n",
    "                              workers=10,\n",
    "                              use_multiprocessing=True,\n",
    "                              steps_per_epoch=20, \n",
    "                              validation_steps=10,\n",
    "                             callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 889,
     "status": "ok",
     "timestamp": 1554498795616,
     "user": {
      "displayName": "Eoghan Keany",
      "photoUrl": "",
      "userId": "01744055321449573695"
     },
     "user_tz": -60
    },
    "id": "68lF6bUhPcD5",
    "outputId": "d1cd4f0d-23b9-4e10-cc9b-723ac203e1cc"
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Training and Validation Losses',size = 20)\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UdebpAkhTJ62",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train_trm = emb_model.predict(X_train.reshape(-1, sent_emb, 1))\n",
    "X_test_trm = emb_model.predict(X_test.reshape(-1, sent_emb, 1))\n",
    "X_train.shape, X_train_trm.shape, X_test.shape, X_test_trm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter(x, labels, subtitle=None):\n",
    "    palette = np.array(sns.color_palette(\"hls\", 500))\n",
    "    f = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot(aspect='equal')\n",
    "    sc = ax.scatter(x[:,0], x[:,1], lw=0,alpha = 0.5, s=40, c=palette[labels.astype(np.int)])\n",
    "    plt.xlim(-25, 25)\n",
    "    plt.ylim(-25, 25)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSNE to use dimensionality reduction to visulaise the resultant embeddings\n",
    "tsne = TSNE()\n",
    "train_tsne = tsne.fit_transform(X_train)\n",
    "print(train_tsne.shape, y_train.shape)\n",
    "scatter(train_tsne, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1373,
     "status": "ok",
     "timestamp": 1554498980246,
     "user": {
      "displayName": "Eoghan Keany",
      "photoUrl": "",
      "userId": "01744055321449573695"
     },
     "user_tz": -60
    },
    "id": "ElmyqDG0o8te",
    "outputId": "abcda512-218a-4a5c-95ca-1872e80a1c48"
   },
   "outputs": [],
   "source": [
    "tsne = TSNE()\n",
    "train_tsne_embeds = tsne.fit_transform(X_train_trm)\n",
    "print(train_tsne_embeds.shape, y_train.shape)\n",
    "scatter(train_tsne_embeds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE()\n",
    "test_tsne = tsne.fit_transform(X_test)\n",
    "print(test_tsne.shape, y_test.shape)\n",
    "scatter(test_tsne, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE()\n",
    "test_tsne_embeds = tsne.fit_transform(X_test_trm)\n",
    "print(test_tsne_embeds.shape, y_test.shape)\n",
    "scatter(test_tsne_embeds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=3)\n",
    "train_to_classify = tsne.fit_transform(X_train_trm)\n",
    "test_to_classify = tsne.fit_transform(X_test_trm)\n",
    "\n",
    "train_to_classify.shape, test_to_classify.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pymedtermino\n",
    "\n",
    "from metric_learn import NCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "generations = 3\n",
    "population_size = 20\n",
    "max_eval_time_mins = 1\n",
    "n_jobs = 10\n",
    "max_iter = 10\n",
    "\n",
    "tpot = TPOTClassifier(generations=generations, \n",
    "                      population_size=population_size,\n",
    "                      verbosity=2, \n",
    "                      random_state=42, \n",
    "                      max_eval_time_mins=max_eval_time_mins, \n",
    "                      n_jobs=n_jobs)\n",
    "\n",
    "tpot.fit(train_tsne_embeds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = tpot.score(train_tsne_embeds, y_train)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = tpot.score(test_tsne_embeds, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "score was with low alpha = 0.17439703153988867\n",
    "score was with 0.2 alpha = 0.11873840445269017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([2, 3 , 4, 5, 1, 2, 0 ,1, 2])\n",
    "d = np.array([324, 656, 55453, 2342, 5464, 3244, 23, 545, 23243])\n",
    "\n",
    "y[np.argmin(d)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([1, 2, 2, 1, 0 ,0 ,0, 1]*3)\n",
    "d = np.array([2333, 232, 13423, 32423 ,234324, 234, 4545, 23]*3)\n",
    "\n",
    "np.argpartition(d, y.shape[0]-1)[:], y[np.argpartition(d, y.shape[0]-1)[:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3902,
     "status": "ok",
     "timestamp": 1554498988856,
     "user": {
      "displayName": "Eoghan Keany",
      "photoUrl": "",
      "userId": "01744055321449573695"
     },
     "user_tz": -60
    },
    "id": "UrLLhmrg0Vme",
    "outputId": "5a1e047c-b49e-4617-ff24-12c625a8a4f1"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Dropout, Flatten, Convolution2D, MaxPooling2D,ZeroPadding2D\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a Classifier that computes the class of a specific embedding. \n",
    "Classifier_input = Input((10,))\n",
    "Classifier_output = Dense(10, activation='softmax')(Classifier_input)\n",
    "Classifier_model = Model(Classifier_input, Classifier_output)\n",
    "\n",
    "# convert the target labels to onehot encoded vectors.\n",
    "Y_train_onehot = np_utils.to_categorical(y_train, 10)[:sample_size]\n",
    "Y_test_onehot = np_utils.to_categorical(y_test, 10)[:sample_size]\n",
    "\n",
    "Classifier_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "Classifier_model.fit(X_train_trm,Y_train_onehot, validation_data=(X_test_trm,Y_test_onehot),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12823,
     "status": "ok",
     "timestamp": 1553884638254,
     "user": {
      "displayName": "Eoghan Keany",
      "photoUrl": "",
      "userId": "01744055321449573695"
     },
     "user_tz": 0
    },
    "id": "cNMqm62k8AOE",
    "outputId": "ed9f6d94-2327-46cb-b4d7-c21535566f53"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "# import io\n",
    "# uploaded = files.upload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 691,
     "status": "ok",
     "timestamp": 1553884711533,
     "user": {
      "displayName": "Eoghan Keany",
      "photoUrl": "",
      "userId": "01744055321449573695"
     },
     "user_tz": 0
    },
    "id": "h9dUdWPv86e5",
    "outputId": "80f678b3-55f0-401c-f76b-1135b0189a33"
   },
   "outputs": [],
   "source": [
    "# def gini(x):\n",
    "#     # calculates the gini coeffiecent of \n",
    "#     # an array. \n",
    "#     mad = np.abs(np.subtract.outer(x, x)).mean()\n",
    "#     rmad = mad/np.mean(x)\n",
    "#     g = 0.5 * rmad\n",
    "#     return g\n",
    "\n",
    "# def DigitOrNumber(x):\n",
    "#   # Creates an embedding for an image and then calculates the \n",
    "#   # equality of the softmax prediction distribution if it is below a certain threshold\n",
    "#   # then the image will be classified as a digit\n",
    "#   temp = base_model.predict(x)\n",
    "#   temp = Classifier_model.predict(temp)\n",
    "#   if gini(temp) < 0.87:\n",
    "#     print(np.argmax(temp))\n",
    "#   else:\n",
    "#     print('Input is not a Digit')\n",
    "    \n",
    "# # a few examples\n",
    "# x= np.load(io.BytesIO(uploaded['emnist_train_images_3 (1).npy'])) \n",
    "# DigitOrNumber(x[0:1])\n",
    "# DigitOrNumber(x[1:2])\n",
    "# DigitOrNumber(x[2:3])\n",
    "# DigitOrNumber(X_test[20:21])\n",
    "# DigitOrNumber(X_test[500:501])\n",
    "# DigitOrNumber(X_test[1007:1008])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MachinePart1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
