{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from metric_learn import NCA\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from gensim.models import FastText\n",
    "from gensim.test.utils import common_texts\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(f'../../')\n",
    "\n",
    "from src.data.sentence_vectorizer import SentenceVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectorizer: sent2vec\n",
      "work with smm4h21\n",
      "\ttest with smm4h21 score: 0.03498542274052478\n",
      "\ttest with smm4h17 score: 0.0012004801920768306\n",
      "\ttest with psytar score: 0.0\n",
      "\ttest with cadec score: 0.00340522133938706\n",
      "\n",
      "work with smm4h17\n",
      "\ttest with smm4h21 score: 0.011661807580174927\n",
      "\ttest with smm4h17 score: 0.22488995598239295\n",
      "\ttest with psytar score: 0.08395989974937343\n",
      "\ttest with cadec score: 0.015891032917139614\n",
      "\n",
      "work with psytar\n",
      "\ttest with smm4h21 score: 0.008746355685131196\n",
      "\ttest with smm4h17 score: 0.08323329331732693\n",
      "\ttest with psytar score: 0.14661654135338345\n",
      "\ttest with cadec score: 0.0022701475595913734\n",
      "\n",
      "work with cadec\n",
      "\ttest with smm4h21 score: 0.0\n",
      "\ttest with smm4h17 score: 0.023609443777511004\n",
      "\ttest with psytar score: 0.0012531328320802004\n",
      "\ttest with cadec score: 0.13847900113507378\n",
      "\n",
      "vectorizer: fasttext\n",
      "work with smm4h21\n",
      "\ttest with smm4h21 score: 0.27988338192419826\n",
      "\ttest with smm4h17 score: 0.125250100040016\n",
      "\ttest with psytar score: 0.09147869674185463\n",
      "\ttest with cadec score: 0.10669693530079455\n",
      "\n",
      "work with smm4h17\n",
      "\ttest with smm4h21 score: 0.16034985422740525\n",
      "\ttest with smm4h17 score: 0.6946778711484594\n",
      "\ttest with psytar score: 0.20802005012531327\n",
      "\ttest with cadec score: 0.20317820658342792\n",
      "\n",
      "work with psytar\n",
      "\ttest with smm4h21 score: 0.12536443148688048\n",
      "\ttest with smm4h17 score: 0.29571828731492594\n",
      "\ttest with psytar score: 0.4598997493734336\n",
      "\ttest with cadec score: 0.17707150964812712\n",
      "\n",
      "work with cadec\n",
      "\ttest with smm4h21 score: 0.11078717201166181\n",
      "\ttest with smm4h17 score: 0.13885554221688676\n",
      "\ttest with psytar score: 0.13032581453634084\n",
      "\ttest with cadec score: 0.5153234960272418\n",
      "\n",
      "vectorizer: bert\n",
      "work with smm4h21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "100%|██████████| 1369/1369 [03:32<00:00,  6.43it/s]\n",
      "100%|██████████| 343/343 [00:53<00:00,  6.40it/s]\n",
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.00it/s]\n",
      "100%|██████████| 343/343 [00:52<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ttest with smm4h21 score: 0.19825072886297376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "100%|██████████| 1/1 [00:00<00:00,  8.58it/s]\n",
      " 21%|██        | 514/2499 [01:00<03:50,  8.60it/s]"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv('../../data/interim/meddra_codes_terms_synonims.csv')\n",
    "labels = labels['CODE']\n",
    "meddra_labels = {v:k for k, v in enumerate(labels.unique())}\n",
    "\n",
    "results = {\n",
    "    'vectorizer': [],\n",
    "    'train_model': [],\n",
    "    'smm4h21': [],\n",
    "    'smm4h17': [],\n",
    "    'psytar': [],\n",
    "    'cadec': [],\n",
    "}\n",
    "\n",
    "SIZE = 100\n",
    "sv = SentenceVectorizer()\n",
    "for vectorizer_name in sv.get_availables_vectorizers():\n",
    "    print(f\"vectorizer: {vectorizer_name}\")\n",
    "    results['vectorizer'] += [vectorizer_name] * 4\n",
    "    path = '../../data/interim/'\n",
    "    for name_train in os.listdir(path):\n",
    "\n",
    "        if name_train not in ['smm4h17', 'smm4h21', 'psytar', 'cadec']:\n",
    "            continue\n",
    "        print(f\"work with {name_train}\")\n",
    "        results['train_model'].append(name_train)\n",
    "\n",
    "        folder = os.path.join(path, name_train)\n",
    "        corpus_train = folder + '/train.csv'\n",
    "        train = pd.read_csv(corpus_train)\n",
    "        \n",
    "        train = sv.vectorize(train, vectorizer_name=vectorizer_name) \n",
    "\n",
    "        X_train, y_train = train['term_vec'], train['code']\n",
    "        X_train = pd.DataFrame([pd.Series(x) for x in X_train])\n",
    "        y_train = y_train.apply(lambda x: int(meddra_labels[x]))\n",
    "\n",
    "        #clf = make_pipeline(NCA(), SVC(gamma='scale'))\n",
    "        clf = SVC(kernel='poly', gamma='scale')\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        for name_test in os.listdir(path):\n",
    "            if name_test not in ['smm4h17', 'smm4h21', 'psytar', 'cadec']:\n",
    "                continue\n",
    "            folder = os.path.join(path, name_test)\n",
    "            corpus_train = folder + '/train.csv'\n",
    "            corpus_test = folder + '/test.csv'\n",
    "            train, test = pd.read_csv(corpus_train)[:1], pd.read_csv(corpus_test)\n",
    "#            sv = SentenceVectorizer()\n",
    "            _, test = sv.vectorize(train, test, vectorizer_name=vectorizer_name) \n",
    "            X_test, y_test = test['term_vec'], test['code']\n",
    "            X_test = pd.DataFrame([pd.Series(x) for x in X_test])\n",
    "            y_test = y_test.apply(lambda x: int(meddra_labels[x]))\n",
    "\n",
    "            score = clf.score(X_test, y_test)\n",
    "            print(f'\\ttest with {name_test} score:', score)\n",
    "            results[name_test].append(score)\n",
    "        print()\n",
    "    \n",
    "results = pd.DataFrame(results)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>train_model</th>\n",
       "      <th>smm4h21</th>\n",
       "      <th>smm4h17</th>\n",
       "      <th>psytar</th>\n",
       "      <th>cadec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sent2vec</td>\n",
       "      <td>smm4h21</td>\n",
       "      <td>0.034985</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sent2vec</td>\n",
       "      <td>smm4h17</td>\n",
       "      <td>0.011662</td>\n",
       "      <td>0.224890</td>\n",
       "      <td>0.083960</td>\n",
       "      <td>0.015891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sent2vec</td>\n",
       "      <td>psytar</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>0.083233</td>\n",
       "      <td>0.146617</td>\n",
       "      <td>0.002270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sent2vec</td>\n",
       "      <td>cadec</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023609</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.138479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fasttext</td>\n",
       "      <td>smm4h21</td>\n",
       "      <td>0.279883</td>\n",
       "      <td>0.125250</td>\n",
       "      <td>0.091479</td>\n",
       "      <td>0.106697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>fasttext</td>\n",
       "      <td>smm4h17</td>\n",
       "      <td>0.160350</td>\n",
       "      <td>0.694678</td>\n",
       "      <td>0.208020</td>\n",
       "      <td>0.203178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fasttext</td>\n",
       "      <td>psytar</td>\n",
       "      <td>0.125364</td>\n",
       "      <td>0.295718</td>\n",
       "      <td>0.459900</td>\n",
       "      <td>0.177072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fasttext</td>\n",
       "      <td>cadec</td>\n",
       "      <td>0.110787</td>\n",
       "      <td>0.138856</td>\n",
       "      <td>0.130326</td>\n",
       "      <td>0.515323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bert</td>\n",
       "      <td>smm4h21</td>\n",
       "      <td>0.198251</td>\n",
       "      <td>0.046018</td>\n",
       "      <td>0.039861</td>\n",
       "      <td>0.041045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bert</td>\n",
       "      <td>smm4h17</td>\n",
       "      <td>0.023324</td>\n",
       "      <td>0.738295</td>\n",
       "      <td>0.060659</td>\n",
       "      <td>0.021144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bert</td>\n",
       "      <td>psytar</td>\n",
       "      <td>0.055394</td>\n",
       "      <td>0.124050</td>\n",
       "      <td>0.363951</td>\n",
       "      <td>0.075871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bert</td>\n",
       "      <td>cadec</td>\n",
       "      <td>0.064140</td>\n",
       "      <td>0.032813</td>\n",
       "      <td>0.112652</td>\n",
       "      <td>0.354478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   vectorizer train_model   smm4h21   smm4h17    psytar     cadec\n",
       "0    sent2vec     smm4h21  0.034985  0.001200  0.000000  0.003405\n",
       "1    sent2vec     smm4h17  0.011662  0.224890  0.083960  0.015891\n",
       "2    sent2vec      psytar  0.008746  0.083233  0.146617  0.002270\n",
       "3    sent2vec       cadec  0.000000  0.023609  0.001253  0.138479\n",
       "4    fasttext     smm4h21  0.279883  0.125250  0.091479  0.106697\n",
       "5    fasttext     smm4h17  0.160350  0.694678  0.208020  0.203178\n",
       "6    fasttext      psytar  0.125364  0.295718  0.459900  0.177072\n",
       "7    fasttext       cadec  0.110787  0.138856  0.130326  0.515323\n",
       "8        bert     smm4h21  0.198251  0.046018  0.039861  0.041045\n",
       "9        bert     smm4h17  0.023324  0.738295  0.060659  0.021144\n",
       "10       bert      psytar  0.055394  0.124050  0.363951  0.075871\n",
       "11       bert       cadec  0.064140  0.032813  0.112652  0.354478"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generations = 2\n",
    "# population_size = 50\n",
    "# max_eval_time_mins = 2\n",
    "# n_jobs = 10\n",
    "# max_iter = 10\n",
    "\n",
    "# tpot = TPOTClassifier(generations=generations, \n",
    "#                       population_size=population_size,\n",
    "#                       verbosity=2, \n",
    "#                       random_state=42, \n",
    "#                       max_eval_time_mins=max_eval_time_mins, \n",
    "#                       n_jobs=n_jobs)\n",
    "\n",
    "# tpot.fit(X_train, y_train)\n",
    "# score = tpot.score(X_test, y_test)\n",
    "# score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
