{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from copy import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from textaugment import Wordnet, EDA\n",
    "import nlpaug.augmenter.word as naw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import sys\n",
    "sys.path.append(f'../../')\n",
    "\n",
    "from src.features.parallelize import apply_parallel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_and_explode_syn(df):\n",
    "    df['term'] = df.apply(\n",
    "        #lambda row: [row['STR']] + [i for i in list(set(eval(row['SNMS'])))[:3] if i.lower() != row['STR'].lower()], axis=1)\n",
    "        lambda row: [row['STR']] + [i for i in list(set(eval(row['SNMS'])))[:3] if i.lower() != row['STR'].lower()], axis=1)\n",
    "    return df\n",
    "\n",
    "def concat_and_explode(df):\n",
    "    df['term'] = df.apply(\n",
    "        lambda row: [row['STR']], axis=1)\n",
    "    return df\n",
    "\n",
    "def clear_spec_symb(df):\n",
    "    ps = [r'\\(.*?\\)', 'NOS', r'\\[.*?\\]', ':', '\\,']\n",
    "    for pattern in ps:\n",
    "        df['term'] = df['term'].apply(\n",
    "            lambda row: re.sub(pattern, '', row))\n",
    "\n",
    "    df['term'] = df['term'].apply(\n",
    "            lambda row: ' '.join(set(row.lower().split(' '))))\n",
    "    df = df[df['term'] != ''].drop_duplicates(subset=['term', 'code'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ventilation pneumonitis</td>\n",
       "      <td>10000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-beta-hydroxylase deficiency</td>\n",
       "      <td>10000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11-oxysteroid activity incr</td>\n",
       "      <td>10000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11-oxysteroid activity increased</td>\n",
       "      <td>10000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17 ketosteroids urine</td>\n",
       "      <td>10000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84208</th>\n",
       "      <td>Infective pneumonia (SMQ)</td>\n",
       "      <td>20000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84209</th>\n",
       "      <td>Dehydration (SMQ)</td>\n",
       "      <td>20000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84210</th>\n",
       "      <td>['Hypokalaemia (SMQ)' 'Hypokalemia (SMQ)']</td>\n",
       "      <td>20000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84211</th>\n",
       "      <td>Sepsis (SMQ)</td>\n",
       "      <td>20000234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84212</th>\n",
       "      <td>Opportunistic infections (SMQ)</td>\n",
       "      <td>20000235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84213 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             term      code\n",
       "0                         Ventilation pneumonitis  10000001\n",
       "1                  11-beta-hydroxylase deficiency  10000002\n",
       "2                     11-oxysteroid activity incr  10000003\n",
       "3                11-oxysteroid activity increased  10000004\n",
       "4                           17 ketosteroids urine  10000005\n",
       "...                                           ...       ...\n",
       "84208                   Infective pneumonia (SMQ)  20000231\n",
       "84209                           Dehydration (SMQ)  20000232\n",
       "84210  ['Hypokalaemia (SMQ)' 'Hypokalemia (SMQ)']  20000233\n",
       "84211                                Sepsis (SMQ)  20000234\n",
       "84212              Opportunistic infections (SMQ)  20000235\n",
       "\n",
       "[84213 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdr_codes_to_exp = pd.read_csv('../../data/interim/meddra_codes_terms_synonims.csv')\n",
    "mdr_codes_to_exp = mdr_codes_to_exp[['STR', 'SNMS', 'CODE']]\n",
    "mdr_codes_to_exp = apply_parallel(mdr_codes_to_exp, concat_and_explode)\n",
    "mdr_codes_to_exp = mdr_codes_to_exp.explode('term')[['term', 'CODE']].rename(columns={'CODE': 'code'})\n",
    "mdr_codes_to_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ventilation pneumonitis</td>\n",
       "      <td>10000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Humidifier lung</td>\n",
       "      <td>10000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Air-conditioner and humidifier lung</td>\n",
       "      <td>10000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Air conditioner lung</td>\n",
       "      <td>10000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11-beta-hydroxylase deficiency</td>\n",
       "      <td>10000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84208</th>\n",
       "      <td>Infective pneumonia (SMQ)</td>\n",
       "      <td>20000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84209</th>\n",
       "      <td>Dehydration (SMQ)</td>\n",
       "      <td>20000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84210</th>\n",
       "      <td>['Hypokalaemia (SMQ)' 'Hypokalemia (SMQ)']</td>\n",
       "      <td>20000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84211</th>\n",
       "      <td>Sepsis (SMQ)</td>\n",
       "      <td>20000234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84212</th>\n",
       "      <td>Opportunistic infections (SMQ)</td>\n",
       "      <td>20000235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188606 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             term      code\n",
       "0                         Ventilation pneumonitis  10000001\n",
       "0                                 Humidifier lung  10000001\n",
       "0             Air-conditioner and humidifier lung  10000001\n",
       "0                            Air conditioner lung  10000001\n",
       "1                  11-beta-hydroxylase deficiency  10000002\n",
       "...                                           ...       ...\n",
       "84208                   Infective pneumonia (SMQ)  20000231\n",
       "84209                           Dehydration (SMQ)  20000232\n",
       "84210  ['Hypokalaemia (SMQ)' 'Hypokalemia (SMQ)']  20000233\n",
       "84211                                Sepsis (SMQ)  20000234\n",
       "84212              Opportunistic infections (SMQ)  20000235\n",
       "\n",
       "[188606 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdr_codes_to_exp = pd.read_csv('../../data/interim/meddra_codes_terms_synonims.csv')\n",
    "mdr_codes_to_exp = mdr_codes_to_exp[['STR', 'SNMS', 'CODE']]\n",
    "mdr_codes_to_exp = apply_parallel(mdr_codes_to_exp, concat_and_explode_syn)\n",
    "mdr_codes_to_exp = mdr_codes_to_exp.explode('term')[['term', 'CODE']].rename(columns={'CODE': 'code'})\n",
    "mdr_codes_to_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ventilation pneumonitis</td>\n",
       "      <td>10000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Humidifier lung</td>\n",
       "      <td>10000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Air-conditioner and humidifier lung</td>\n",
       "      <td>10000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Air conditioner lung</td>\n",
       "      <td>10000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11hydroxylase deficiency</td>\n",
       "      <td>10000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84207</th>\n",
       "      <td>['Non-haematological tumours of unspecified ma...</td>\n",
       "      <td>20000230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84208</th>\n",
       "      <td>Infective pneumonia</td>\n",
       "      <td>20000231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84209</th>\n",
       "      <td>Dehydration</td>\n",
       "      <td>20000232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84211</th>\n",
       "      <td>Sepsis</td>\n",
       "      <td>20000234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84212</th>\n",
       "      <td>Opportunistic infections</td>\n",
       "      <td>20000235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155883 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    term      code\n",
       "0                                Ventilation pneumonitis  10000001\n",
       "0                                        Humidifier lung  10000001\n",
       "0                    Air-conditioner and humidifier lung  10000001\n",
       "0                                   Air conditioner lung  10000001\n",
       "1                               11hydroxylase deficiency  10000002\n",
       "...                                                  ...       ...\n",
       "84207  ['Non-haematological tumours of unspecified ma...  20000230\n",
       "84208                                Infective pneumonia  20000231\n",
       "84209                                        Dehydration  20000232\n",
       "84211                                             Sepsis  20000234\n",
       "84212                           Opportunistic infections  20000235\n",
       "\n",
       "[155883 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clearing(x):\n",
    "    x = re.sub('\\[.*\\]', '', x)\n",
    "    x = re.sub('\\(.*\\)', '', x)\n",
    "    x = re.sub('-.*-', '', x)\n",
    "    x = x.replace('%', 'percent')\n",
    "    x = x.replace(':', '')\n",
    "    for abb in ['NOS', 'HOH', 'URS', 'AAOOR']:\n",
    "        x = x.replace(abb, '')\n",
    "    x = x.strip()\n",
    "    return x\n",
    "\n",
    "mdr_codes_to_exp['term'] = mdr_codes_to_exp['term'].apply(lambda x: clearing(x))\n",
    "mdr_codes_to_exp = mdr_codes_to_exp.drop_duplicates()\n",
    "mdr_codes_to_exp = mdr_codes_to_exp[mdr_codes_to_exp['term'] != '']\n",
    "mdr_codes_to_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_used_codes_cadec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0421d81946fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_used_codes_cadec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_used_codes_psytar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_used_codes_smm4h21\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_used_codes_smm4h17\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_used_codes_cadec' is not defined"
     ]
    }
   ],
   "source": [
    "all_used_codes_cadec.shape, all_used_codes_psytar.shape, all_used_codes_smm4h21.shape, all_used_codes_smm4h17.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_codes = np.concatenate([\n",
    "    all_used_codes_cadec, all_used_codes_psytar, all_used_codes_smm4h21, all_used_codes_smm4h17\n",
    "]) #.shape\n",
    "used_codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(used_codes).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdr_codes_to_exp = mdr_codes_to_exp[mdr_codes_to_exp['code'].isin(np.unique(used_codes))]\n",
    "mdr_codes_to_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdr_codes_to_exp = pd.read_csv('../../data/interim/meddra_codes_terms_synonims.csv').rename(columns={'CODE': 'code'})\n",
    "mdr_codes_to_exp.to_csv('../../data/interim/used_codes_big.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdr_codes_to_exp = mdr_codes_to_exp[mdr_codes_to_exp['code'].isin(np.unique(used_codes))]\n",
    "mdr_codes_to_exp.to_csv('../../data/interim/used_codes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdr_codes_to_exp[mdr_codes_to_exp['code'].isin(np.unique(used_codes))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_wdnt = naw.SynonymAug(aug_src='wordnet')\n",
    "aug_ppdb = naw.SynonymAug(aug_src='ppdb', model_path='../../data/external/embeddings/ppdb-2.0-tldr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_rareness = 6\n",
    "\n",
    "def get_ready_data(df_train, df_val, name, use_clear=True):\n",
    "    dict_concepts = mdr_cod_to_norm[['STR', 'CODE']].rename(columns={'CODE':'code', 'STR':'term'})\n",
    "    if use_clear: \n",
    "        df_train = clear_spec_symb(df_train)\n",
    "    df_train.to_csv(f'../../data/interim/{name}/train_pure.csv', index=False)\n",
    "    df_val.to_csv(f'../../data/interim/{name}/test.csv', index=False)\n",
    "    print(f\"train: {df_train.shape} / test: {df_val.shape}\")\n",
    "    \n",
    "    df_train_aug = copy(df_train)\n",
    "    t = Wordnet()\n",
    "    df_train_aug['term'] = df_train_aug['term'].progress_apply(lambda mention: t.augment(mention))\n",
    "    df_train_aug = pd.concat([df_train_aug, df_train])[['term', 'code']]\n",
    "    df_train_aug.to_csv(f'../../data/interim/{name}/train_aug.csv', index=False)\n",
    "    print(f\"train augmented textaugment wdnt: {df_train_aug.shape}\")\n",
    "    \n",
    "    df_train_aug_wdnt = copy(df_train)\n",
    "    df_train_aug_wdnt['term'] = df_train_aug_wdnt['term'].progress_apply(lambda mention: aug_wdnt.augment(mention))\n",
    "    df_train_aug_wdnt = pd.concat([df_train_aug_wdnt, df_train])[['term', 'code']]\n",
    "    df_train_aug_wdnt.to_csv(f'../../data/interim/{name}/train_aug_wdnt.csv', index=False)\n",
    "    print(f\"train augmented nlpaug wdnt: {df_train_aug_wdnt.shape}\")\n",
    "          \n",
    "    df_train_aug_ppdb = copy(df_train)\n",
    "    df_train_aug_ppdb['term'] = df_train_aug_ppdb['term'].progress_apply(lambda mention: aug_ppdb.augment(mention))\n",
    "    df_train_aug_ppdb = pd.concat([df_train_aug_ppdb, df_train])[['term', 'code']]\n",
    "    df_train_aug_ppdb.to_csv(f'../../data/interim/{name}/train_aug_ppdb.csv', index=False)\n",
    "    print(f\"train augmented nlpaug ppdb: {df_train_aug_ppdb.shape}\")\n",
    "        \n",
    "    for n_runs in [2, 3]:\n",
    "        df_train_aug = copy(df_train)\n",
    "        t = Wordnet(v=True ,n=True, runs=n_runs)\n",
    "        \n",
    "        indices_inferior = df_train_aug['code'].value_counts()[df_train_aug['code'].value_counts() < N_rareness].index\n",
    "        df_train_aug = df_train_aug[df_train_aug['code'].isin(indices_inferior)]\n",
    "        \n",
    "        multiple_times_augmented = []\n",
    "        for i in range(5):\n",
    "            df_train_aug['term'] = df_train_aug['term'].progress_apply(lambda mention: t.augment(mention))\n",
    "            multiple_times_augmented.append(df_train_aug)\n",
    "            \n",
    "        df_train_aug = pd.concat(multiple_times_augmented)\n",
    "        df_train_aug = pd.concat([df_train_aug, df_train])[['term', 'code']]\n",
    "        df_train_aug = df_train_aug.drop_duplicates(subset=['term', 'code'], keep='last')\n",
    "        df_train_aug.to_csv(f'../../data/interim/{name}/train_textaug_wdnt_{n_runs}_repl.csv', index=False)\n",
    "        print(f\"train augmented textaugment wdnt repl {n_runs}: {df_train_aug.shape}\")  \n",
    "        \n",
    "    df_train_aug = copy(df_train)\n",
    "    t = EDA() \n",
    "    indices_inferior = df_train_aug['code'].value_counts()[df_train_aug['code'].value_counts() < N_rareness].index\n",
    "    df_train_aug = df_train_aug[df_train_aug['code'].isin(indices_inferior)]\n",
    "    def augment_insertion(mention):\n",
    "        try:\n",
    "            return t.random_insertion(mention)\n",
    "        except Exception as e:\n",
    "            return mention\n",
    "    df_train_aug['term'] = df_train_aug['term'].progress_apply(augment_insertion)\n",
    "    df_train_aug = pd.concat([df_train_aug, df_train])[['term', 'code']]\n",
    "    df_train_aug = df_train_aug.drop_duplicates(subset=['term', 'code'], keep='last')\n",
    "    df_train_aug.to_csv(f'../../data/interim/{name}/train_textaug_wdnt_insrt.csv', index=False)\n",
    "    print(f\"train augmented textaugment wdnt insrt: {df_train_aug.shape}\")  \n",
    "    \n",
    "\n",
    "    df_train_aug = copy(df_train)\n",
    "    t = EDA() \n",
    "    indices_inferior = df_train_aug['code'].value_counts()[df_train_aug['code'].value_counts() < N_rareness].index\n",
    "    df_train_aug = df_train_aug[df_train_aug['code'].isin(indices_inferior)]\n",
    "    def augment_insertion(mention):\n",
    "        try:\n",
    "            return t.random_insertion(mention)\n",
    "        except Exception as e:\n",
    "            return mention\n",
    "    df_train_aug['term'] = df_train_aug['term'].progress_apply(augment_insertion)\n",
    "    df_train_aug = pd.concat([df_train_aug, df_train])\n",
    "    df_train_aug['SNMS'] = df_train_aug['SNMS'].apply(lambda row: list(set(eval(row))))\n",
    "    df_train_aug = df_train_aug[[\"code\", 'STR', 'SNMS']]\n",
    "    df_train_aug['term'] = df_train_aug.progress_apply(\n",
    "        lambda x: ' '.join(list(set([x['STR']] + x['SNMS']))), axis=1)\n",
    "    df_train_aug = df_train_aug[['term', 'code']]\n",
    "    df_train_aug = pd.concat([df_train, df_train_aug])[['term', 'code']]\n",
    "    if use_clear: \n",
    "        df_train_aug = clear_spec_symb(df_train_aug)\n",
    "    df_train_aug = df_train_aug[['term', 'code']].drop_duplicates(subset=['term', 'code'], keep='last')\n",
    "    df_train_aug.to_csv(f'../../data/interim/{name}/train_textaug_wdnt_insrt_retro.csv', index=False)\n",
    "    print(f\"train augmented textaugment wdnt insrt CONCEPT_RETRO: {df_train_aug.shape}\")  \n",
    "    \n",
    "    df_train_concept = copy(df_train)\n",
    "    df_train_concept['term'] = df_train_concept.progress_apply(lambda row: [row['term'], row['STR']], axis=1)\n",
    "    df_train_concept = df_train_concept[['term', 'code']].explode('term')\n",
    "    if use_clear: \n",
    "        df_train_concept = clear_spec_symb(df_train_concept)\n",
    "    df_train_concept.to_csv(f'../../data/interim/{name}/train_concept.csv', index=False)\n",
    "    print(f\"train concept: {df_train_concept.shape}\")\n",
    "\n",
    "    df_train_concept_retro = copy(df_train)\n",
    "    df_train_concept_retro['SNMS'] = df_train_concept_retro['SNMS'].apply(lambda row: list(set(eval(row))))\n",
    "    df_train_concept_retro = df_train_concept_retro[[\"code\", 'STR', 'SNMS']]\n",
    "    df_train_concept_retro['term'] = df_train_concept_retro.progress_apply(\n",
    "        lambda x: ' '.join(list(set([x['STR']] + x['SNMS']))), axis=1)\n",
    "    df_train_concept_retro = df_train_concept_retro[['term', 'code']]\n",
    "    df_train_concept_retro = pd.concat([df_train, df_train_concept_retro])[['term', 'code']]\n",
    "    if use_clear: \n",
    "        df_train_concept_retro = clear_spec_symb(df_train_concept_retro)\n",
    "    df_train_concept_retro.to_csv(f'../../data/interim/{name}/train_concept_retro.csv', index=False)\n",
    "    print(f\"train concept retro: {df_train_concept_retro.shape}\")\n",
    "\n",
    "    df_train_all_internal = copy(df_train)\n",
    "    df_train_all_internal['SNMS'] = df_train_all_internal['SNMS'].progress_apply(lambda row: eval(row))\n",
    "    df_train_all_internal['term'] = df_train_all_internal.progress_apply(lambda x: list(set([x['STR']] + x['SNMS'])), axis=1)\n",
    "    df_train_all_internal = df_train_all_internal[['term', 'code']]\n",
    "    df_train_all_internal = df_train_all_internal.explode('term')\n",
    "    if use_clear: \n",
    "        df_train_all_internal = clear_spec_symb(df_train_all_internal)\n",
    "    df_train_all_internal.to_csv(f'../../data/interim/{name}/train_all_internal.csv', index=False)\n",
    "    print(f\"train all internal: {df_train_all_internal.shape}\")\n",
    "\n",
    "\n",
    "    df_train_big = copy(df_train)\n",
    "    df_train_big = pd.concat([df_train_all_internal, dict_concepts])\n",
    "    if use_clear: \n",
    "        df_train_big = clear_spec_symb(df_train_big)\n",
    "    df_train_big.to_csv(f'../../data/interim/{name}/train_big.csv', index=False)\n",
    "    print(f\"train big: {df_train_big.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMM4H 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "smm4h21_spans_train = pd.read_csv('../../data/external/smm4h_2021/SMM4H_2021_train_spans.tsv', sep='\\t', header=None)\n",
    "smm4h21_tweets_train = pd.read_csv('../../data/external/smm4h_2021/SMM4H_2021_train_tweets.tsv', sep='\\t', header=None)\n",
    "smm4h21_train = smm4h21_spans_train.merge(smm4h21_tweets_train, on=0)\n",
    "\n",
    "smm4h21_spans_val = pd.read_csv('../../data/external/smm4h_2021/SMM4H_2021_val_spans.tsv', sep='\\t', header=None)\n",
    "smm4h21_tweets_val = pd.read_csv('../../data/external/smm4h_2021/SMM4H_2021_val_tweets.tsv', sep='\\t', header=None)\n",
    "smm4h21_val = smm4h21_spans_val.merge(smm4h21_tweets_val, on=0)\n",
    "\n",
    "mdr_codes = pd.read_csv('../../data/interim/meddra_codes_terms_synonims.csv')\n",
    "mdr_cod_to_norm = mdr_codes[['CODE', 'STR', 'SNMS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1512, 7), (287, 7))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRAIN\n",
    "smm4h21_train = smm4h21_train.rename(columns={\n",
    "    4: 'term', '1_y': 'text',\n",
    "    2: 'start', 3: 'end',\n",
    "    5: 'code'\n",
    "})\n",
    "\n",
    "smm4h21_train = smm4h21_train[['term', 'start', 'end', 'text', 'code']]\n",
    "smm4h21_train = smm4h21_train[smm4h21_train['code'].str.isdigit()]\n",
    "smm4h21_train['code'] = smm4h21_train['code'].astype(int)\n",
    "\n",
    "\n",
    "smm4h21_train = pd.merge(smm4h21_train, mdr_cod_to_norm, left_on='code', right_on='CODE', how='left')\n",
    "smm4h21_train = smm4h21_train.drop(columns=['CODE'])\n",
    "\n",
    "\n",
    "# VALIDATION\n",
    "smm4h21_val = smm4h21_val.rename(columns={\n",
    "    4: 'term', '1_y': 'text',\n",
    "    2: 'start', 3: 'end',\n",
    "    5: 'code'\n",
    "})\n",
    "\n",
    "smm4h21_val = smm4h21_val[['term', 'start', 'end', 'text', 'code']]\n",
    "smm4h21_val = smm4h21_val[smm4h21_val['code'].str.isdigit()]\n",
    "smm4h21_val['code'] = smm4h21_val['code'].astype(int)\n",
    "smm4h21_val = pd.merge(smm4h21_val, mdr_cod_to_norm, left_on='code', right_on='CODE', how='left')\n",
    "smm4h21_val = smm4h21_val.drop(columns=['CODE'])\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "smm4h21_train = shuffle(smm4h21_train)\n",
    "\n",
    "n = 200\n",
    "smm4h21_val = pd.concat([smm4h21_val, smm4h21_train.iloc[-n:]])\n",
    "smm4h21_train = smm4h21_train.iloc[:-n]\n",
    "smm4h21_train.shape, smm4h21_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 303/1046 [00:00<00:00, 2916.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (1046, 7) / test: (287, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1046/1046 [00:00<00:00, 3070.90it/s]\n",
      "  0%|          | 2/1046 [00:00<00:53, 19.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented textaugment wdnt: (2092, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1046/1046 [01:46<00:00,  9.80it/s]\n",
      "  0%|          | 2/1046 [00:00<00:52, 19.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented nlpaug wdnt: (2092, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1046/1046 [01:46<00:00,  9.81it/s]\n",
      " 40%|████      | 263/657 [00:00<00:00, 2626.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented nlpaug ppdb: (2092, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:00<00:00, 2564.74it/s]\n",
      "100%|██████████| 657/657 [00:00<00:00, 1120.08it/s]\n",
      "100%|██████████| 657/657 [00:00<00:00, 2482.30it/s]\n",
      "100%|██████████| 657/657 [00:00<00:00, 2449.75it/s]\n",
      "100%|██████████| 657/657 [00:00<00:00, 2711.09it/s]\n",
      " 40%|███▉      | 261/657 [00:00<00:00, 2554.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented textaugment wdnt repl 2: (1518, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 657/657 [00:00<00:00, 2513.03it/s]\n",
      "100%|██████████| 657/657 [00:00<00:00, 2428.67it/s]\n",
      "100%|██████████| 657/657 [00:00<00:00, 2477.85it/s]\n",
      "100%|██████████| 657/657 [00:00<00:00, 2482.27it/s]\n",
      "100%|██████████| 657/657 [00:00<00:00, 2504.26it/s]\n",
      "100%|██████████| 657/657 [00:00<00:00, 6216.94it/s]\n",
      "100%|██████████| 657/657 [00:00<00:00, 14109.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented textaugment wdnt repl 3: (1519, 2)\n",
      "train augmented textaugment wdnt insrt: (1639, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1703/1703 [00:00<00:00, 57267.81it/s]\n",
      "100%|██████████| 1046/1046 [00:00<00:00, 78888.78it/s]\n",
      "  0%|          | 0/1046 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented textaugment wdnt insrt CONCEPT_RETRO: (1486, 2)\n",
      "train concept: (1371, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1046/1046 [00:00<00:00, 67293.12it/s]\n",
      "100%|██████████| 1046/1046 [00:00<00:00, 47017.41it/s]\n",
      "100%|██████████| 1046/1046 [00:00<00:00, 66541.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train concept retro: (1486, 2)\n",
      "train all internal: (2794, 2)\n",
      "train big: (84094, 2)\n"
     ]
    }
   ],
   "source": [
    "get_ready_data(smm4h21_train, smm4h21_val, 'smm4h21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(617,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_used_codes_smm4h21 = np.concatenate([smm4h21_train['code'].unique(), smm4h21_val['code'].unique()])\n",
    "all_used_codes_smm4h21.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMM4H 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_3_normalization_evaluation.txt\n",
      "task_3_normalization_training1.txt\n",
      "task_3_normalization_training2.txt\n",
      "task_3_normalization_training3.txt\n",
      "task_3_normalization_training4.txt\n"
     ]
    }
   ],
   "source": [
    "train_datasets = []\n",
    "test_datasets = []\n",
    "\n",
    "path = '../../data/external/smm4h_2017/text_files_direct/'\n",
    "for file in os.listdir(path):\n",
    "    print(file)\n",
    "    df = pd.read_csv(path + file, sep='\\t', header=None)\n",
    "    if 'train' in file:\n",
    "        train_datasets.append(df)\n",
    "    elif 'eval' in file:\n",
    "        test_datasets.append(df)\n",
    "        \n",
    "smm4h17_train = pd.concat(train_datasets).rename\n",
    "smm4h17_test  = pd.concat(test_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KFU's smm4h17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "smm4h17_spans_train = pd.read_csv('../../data/external/smm4h_2017/smm4h_kfu/processed_train/0.concept', \n",
    "                                  sep='|', header=None).dropna(axis=1)[[7, 9]]\n",
    "smm4h17_spans_test = pd.read_csv('../../data/external/smm4h_2017/smm4h_kfu/processed_test/0.concept', \n",
    "                                  sep='|', header=None).dropna(axis=1)[[7, 9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdr_codes = pd.read_csv('../../data/interim/meddra_codes_terms_synonims.csv')\n",
    "mdr_cod_to_norm = mdr_codes[['CODE', 'STR', 'SNMS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>code</th>\n",
       "      <th>STR</th>\n",
       "      <th>SNMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sleepier</td>\n",
       "      <td>10041349</td>\n",
       "      <td>Somnolence</td>\n",
       "      <td>['Somnolence', 'Somnolence', 'Somnolence', 'So...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dreamt colors</td>\n",
       "      <td>10000125</td>\n",
       "      <td>Abnormal dreams</td>\n",
       "      <td>['Dream disorder', 'Abnormal dreams', 'Abnorma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zombie</td>\n",
       "      <td>10016322</td>\n",
       "      <td>Feeling abnormal</td>\n",
       "      <td>['Feeling abnormal', 'Abnormal feeling', 'Abno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>headache</td>\n",
       "      <td>10019211</td>\n",
       "      <td>Headache</td>\n",
       "      <td>['Headache', 'Headache', 'Headache', 'Headache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crazy</td>\n",
       "      <td>10061920</td>\n",
       "      <td>Psychotic disorder</td>\n",
       "      <td>['Psychotic disorder, NOS', 'Psychotic disorde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>sleptwalk</td>\n",
       "      <td>10041347</td>\n",
       "      <td>Somnambulism</td>\n",
       "      <td>['Somnambulism', 'Somnambulism', 'Somnambulism...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>fatigue</td>\n",
       "      <td>10016256</td>\n",
       "      <td>Fatigue</td>\n",
       "      <td>['Fatigue', 'Fatigue', 'Fatigue', 'Tiredness',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>headache</td>\n",
       "      <td>10019211</td>\n",
       "      <td>Headache</td>\n",
       "      <td>['Headache', 'Headache', 'Headache', 'Headache...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>out of it</td>\n",
       "      <td>10041349</td>\n",
       "      <td>Somnolence</td>\n",
       "      <td>['Somnolence', 'Somnolence', 'Somnolence', 'So...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>no sleep</td>\n",
       "      <td>10022437</td>\n",
       "      <td>Insomnia</td>\n",
       "      <td>['Sleeplessness', 'Sleeplessness', 'Sleeplessn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2499 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               term      code                 STR                                               SNMS\n",
       "0          sleepier  10041349          Somnolence  ['Somnolence', 'Somnolence', 'Somnolence', 'So...\n",
       "1     dreamt colors  10000125     Abnormal dreams  ['Dream disorder', 'Abnormal dreams', 'Abnorma...\n",
       "2            zombie  10016322    Feeling abnormal  ['Feeling abnormal', 'Abnormal feeling', 'Abno...\n",
       "3          headache  10019211            Headache  ['Headache', 'Headache', 'Headache', 'Headache...\n",
       "4             crazy  10061920  Psychotic disorder  ['Psychotic disorder, NOS', 'Psychotic disorde...\n",
       "...             ...       ...                 ...                                                ...\n",
       "2494      sleptwalk  10041347        Somnambulism  ['Somnambulism', 'Somnambulism', 'Somnambulism...\n",
       "2495        fatigue  10016256             Fatigue  ['Fatigue', 'Fatigue', 'Fatigue', 'Tiredness',...\n",
       "2496       headache  10019211            Headache  ['Headache', 'Headache', 'Headache', 'Headache...\n",
       "2497      out of it  10041349          Somnolence  ['Somnolence', 'Somnolence', 'Somnolence', 'So...\n",
       "2498       no sleep  10022437            Insomnia  ['Sleeplessness', 'Sleeplessness', 'Sleeplessn...\n",
       "\n",
       "[2499 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smm4h17_spans_train = smm4h17_spans_train.rename(columns={7: 'term', 9: 'code'})\n",
    "smm4h17_spans_test = smm4h17_spans_test.rename(columns={7: 'term', 9: 'code'})\n",
    "\n",
    "#smm4h17_spans_train = smm4h17_spans_train[smm4h17_spans_train['code'].str.isdigit()]\n",
    "smm4h17_spans_test = smm4h17_spans_test[smm4h17_spans_test['code'].str.isdigit()]\n",
    "\n",
    "smm4h17_spans_train['code'] = smm4h17_spans_train['code'].astype(int)\n",
    "smm4h17_spans_test['code'] = smm4h17_spans_test['code'].astype(int)\n",
    "\n",
    "smm4h17_spans_train = pd.merge(smm4h17_spans_train, mdr_cod_to_norm, left_on='code', right_on='CODE', how='left')\n",
    "smm4h17_spans_train = smm4h17_spans_train.drop(columns=['CODE'])\n",
    "smm4h17_spans_train\n",
    "\n",
    "smm4h17_spans_test = pd.merge(smm4h17_spans_test, mdr_cod_to_norm, left_on='code', right_on='CODE', how='left')\n",
    "smm4h17_spans_test = smm4h17_spans_test.drop(columns=['CODE'])\n",
    "smm4h17_spans_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 421/2774 [00:00<00:00, 4194.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (2774, 4) / test: (2499, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2774/2774 [00:00<00:00, 3403.30it/s]\n",
      "  0%|          | 2/2774 [00:00<02:21, 19.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented textaugment wdnt: (5548, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2774/2774 [04:43<00:00,  9.80it/s]\n",
      "  0%|          | 2/2774 [00:00<02:20, 19.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented nlpaug wdnt: (5548, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2774/2774 [04:42<00:00,  9.81it/s]\n",
      " 39%|███▊      | 282/731 [00:00<00:00, 2815.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented nlpaug ppdb: (5548, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 731/731 [00:00<00:00, 2361.26it/s]\n",
      "100%|██████████| 731/731 [00:00<00:00, 2556.82it/s]\n",
      "100%|██████████| 731/731 [00:00<00:00, 2552.78it/s]\n",
      "100%|██████████| 731/731 [00:00<00:00, 2687.18it/s]\n",
      "100%|██████████| 731/731 [00:00<00:00, 2656.90it/s]\n",
      " 37%|███▋      | 273/731 [00:00<00:00, 2727.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented textaugment wdnt repl 2: (3287, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 731/731 [00:00<00:00, 2316.18it/s]\n",
      "100%|██████████| 731/731 [00:00<00:00, 2244.25it/s]\n",
      "100%|██████████| 731/731 [00:00<00:00, 2349.04it/s]\n",
      "100%|██████████| 731/731 [00:00<00:00, 2275.62it/s]\n",
      "100%|██████████| 731/731 [00:00<00:00, 2322.46it/s]\n",
      "100%|██████████| 731/731 [00:00<00:00, 6433.60it/s]\n",
      "100%|██████████| 731/731 [00:00<00:00, 12026.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented textaugment wdnt repl 3: (3290, 2)\n",
      "train augmented textaugment wdnt insrt: (3418, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3505/3505 [00:00<00:00, 70381.30it/s]\n",
      "100%|██████████| 2774/2774 [00:00<00:00, 78747.35it/s]\n",
      "  0%|          | 0/2774 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented textaugment wdnt insrt CONCEPT_RETRO: (3240, 2)\n",
      "train concept: (3109, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2774/2774 [00:00<00:00, 66384.81it/s]\n",
      "100%|██████████| 2774/2774 [00:00<00:00, 39967.84it/s]\n",
      "100%|██████████| 2774/2774 [00:00<00:00, 68164.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train concept retro: (3240, 2)\n",
      "train all internal: (3064, 2)\n",
      "train big: (84350, 2)\n"
     ]
    }
   ],
   "source": [
    "get_ready_data(smm4h17_spans_train, smm4h17_spans_test, 'smm4h17')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(725,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_used_codes_smm4h17 = np.concatenate([smm4h17_spans_train['code'].unique(), smm4h17_spans_test['code'].unique()])\n",
    "all_used_codes_smm4h17.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMLS micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CUI</th>\n",
       "      <th>LAT</th>\n",
       "      <th>TS</th>\n",
       "      <th>LUI</th>\n",
       "      <th>STT</th>\n",
       "      <th>SUI</th>\n",
       "      <th>ISPREF</th>\n",
       "      <th>AUI</th>\n",
       "      <th>SAUI</th>\n",
       "      <th>SCUI</th>\n",
       "      <th>SDUI</th>\n",
       "      <th>SAB</th>\n",
       "      <th>TTY</th>\n",
       "      <th>CODE</th>\n",
       "      <th>STR</th>\n",
       "      <th>SRL</th>\n",
       "      <th>SUPPRESS</th>\n",
       "      <th>CVF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2276</td>\n",
       "      <td>C0000727</td>\n",
       "      <td>ENG</td>\n",
       "      <td>P</td>\n",
       "      <td>L0000727</td>\n",
       "      <td>VCW</td>\n",
       "      <td>S0584932</td>\n",
       "      <td>N</td>\n",
       "      <td>A0639292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000647</td>\n",
       "      <td>MDR</td>\n",
       "      <td>PT</td>\n",
       "      <td>10000647</td>\n",
       "      <td>Acute abdomen</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2282</td>\n",
       "      <td>C0000727</td>\n",
       "      <td>ENG</td>\n",
       "      <td>P</td>\n",
       "      <td>L0000727</td>\n",
       "      <td>VCW</td>\n",
       "      <td>S0584932</td>\n",
       "      <td>N</td>\n",
       "      <td>A25741630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000647</td>\n",
       "      <td>MDR</td>\n",
       "      <td>LLT</td>\n",
       "      <td>10000647</td>\n",
       "      <td>Acute abdomen</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2296</td>\n",
       "      <td>C0000727</td>\n",
       "      <td>ENG</td>\n",
       "      <td>S</td>\n",
       "      <td>L0161339</td>\n",
       "      <td>PF</td>\n",
       "      <td>S1616740</td>\n",
       "      <td>Y</td>\n",
       "      <td>A25720821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000647</td>\n",
       "      <td>MDR</td>\n",
       "      <td>LLT</td>\n",
       "      <td>10042784</td>\n",
       "      <td>Syndrome abdominal acute</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2299</td>\n",
       "      <td>C0000727</td>\n",
       "      <td>ENG</td>\n",
       "      <td>S</td>\n",
       "      <td>L0161339</td>\n",
       "      <td>VCW</td>\n",
       "      <td>S1616739</td>\n",
       "      <td>Y</td>\n",
       "      <td>A25708511</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000647</td>\n",
       "      <td>MDR</td>\n",
       "      <td>LLT</td>\n",
       "      <td>10000096</td>\n",
       "      <td>Abdominal syndrome acute</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2334</td>\n",
       "      <td>C0000729</td>\n",
       "      <td>ENG</td>\n",
       "      <td>P</td>\n",
       "      <td>L0000729</td>\n",
       "      <td>VC</td>\n",
       "      <td>S0353650</td>\n",
       "      <td>N</td>\n",
       "      <td>A25716812</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10000081</td>\n",
       "      <td>MDR</td>\n",
       "      <td>LLT</td>\n",
       "      <td>10000057</td>\n",
       "      <td>Abdominal cramps</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>256.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112380</th>\n",
       "      <td>11068329</td>\n",
       "      <td>C5244084</td>\n",
       "      <td>ENG</td>\n",
       "      <td>P</td>\n",
       "      <td>L16308084</td>\n",
       "      <td>PF</td>\n",
       "      <td>S19795290</td>\n",
       "      <td>Y</td>\n",
       "      <td>A31790308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10055798</td>\n",
       "      <td>MDR</td>\n",
       "      <td>LLT</td>\n",
       "      <td>10084046</td>\n",
       "      <td>Severe bleeding - GUSTO classification</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112381</th>\n",
       "      <td>11068331</td>\n",
       "      <td>C5244085</td>\n",
       "      <td>ENG</td>\n",
       "      <td>P</td>\n",
       "      <td>L16308140</td>\n",
       "      <td>VC</td>\n",
       "      <td>S19795001</td>\n",
       "      <td>Y</td>\n",
       "      <td>A31790861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10053315</td>\n",
       "      <td>MDR</td>\n",
       "      <td>LLT</td>\n",
       "      <td>10084469</td>\n",
       "      <td>Home isolation</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112382</th>\n",
       "      <td>11068333</td>\n",
       "      <td>C5244086</td>\n",
       "      <td>ENG</td>\n",
       "      <td>P</td>\n",
       "      <td>L16307956</td>\n",
       "      <td>PF</td>\n",
       "      <td>S19794712</td>\n",
       "      <td>Y</td>\n",
       "      <td>A31789860</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10084354</td>\n",
       "      <td>MDR</td>\n",
       "      <td>LLT</td>\n",
       "      <td>10084499</td>\n",
       "      <td>COVID-19 rapid POC test</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112383</th>\n",
       "      <td>11068334</td>\n",
       "      <td>C5244087</td>\n",
       "      <td>ENG</td>\n",
       "      <td>P</td>\n",
       "      <td>L16308134</td>\n",
       "      <td>PF</td>\n",
       "      <td>S19794970</td>\n",
       "      <td>Y</td>\n",
       "      <td>A31790128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10063630</td>\n",
       "      <td>MDR</td>\n",
       "      <td>LLT</td>\n",
       "      <td>10083228</td>\n",
       "      <td>Genital scratch</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112384</th>\n",
       "      <td>11068335</td>\n",
       "      <td>C5244088</td>\n",
       "      <td>ENG</td>\n",
       "      <td>P</td>\n",
       "      <td>L16307902</td>\n",
       "      <td>PF</td>\n",
       "      <td>S19795037</td>\n",
       "      <td>Y</td>\n",
       "      <td>A31789368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10046713</td>\n",
       "      <td>MDR</td>\n",
       "      <td>LLT</td>\n",
       "      <td>10083293</td>\n",
       "      <td>Indiana pouch</td>\n",
       "      <td>3</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112385 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0       CUI  LAT TS        LUI  STT        SUI ISPREF        AUI  SAUI  SCUI      SDUI  SAB  TTY      CODE                                     STR  SRL SUPPRESS    CVF\n",
       "0             2276  C0000727  ENG  P   L0000727  VCW   S0584932      N   A0639292   NaN   NaN  10000647  MDR   PT  10000647                           Acute abdomen    3        N  256.0\n",
       "1             2282  C0000727  ENG  P   L0000727  VCW   S0584932      N  A25741630   NaN   NaN  10000647  MDR  LLT  10000647                           Acute abdomen    3        N  256.0\n",
       "2             2296  C0000727  ENG  S   L0161339   PF   S1616740      Y  A25720821   NaN   NaN  10000647  MDR  LLT  10042784                Syndrome abdominal acute    3        N    NaN\n",
       "3             2299  C0000727  ENG  S   L0161339  VCW   S1616739      Y  A25708511   NaN   NaN  10000647  MDR  LLT  10000096                Abdominal syndrome acute    3        N    NaN\n",
       "4             2334  C0000729  ENG  P   L0000729   VC   S0353650      N  A25716812   NaN   NaN  10000081  MDR  LLT  10000057                        Abdominal cramps    3        N  256.0\n",
       "...            ...       ...  ... ..        ...  ...        ...    ...        ...   ...   ...       ...  ...  ...       ...                                     ...  ...      ...    ...\n",
       "112380    11068329  C5244084  ENG  P  L16308084   PF  S19795290      Y  A31790308   NaN   NaN  10055798  MDR  LLT  10084046  Severe bleeding - GUSTO classification    3        N    NaN\n",
       "112381    11068331  C5244085  ENG  P  L16308140   VC  S19795001      Y  A31790861   NaN   NaN  10053315  MDR  LLT  10084469                          Home isolation    3        N    NaN\n",
       "112382    11068333  C5244086  ENG  P  L16307956   PF  S19794712      Y  A31789860   NaN   NaN  10084354  MDR  LLT  10084499                 COVID-19 rapid POC test    3        N    NaN\n",
       "112383    11068334  C5244087  ENG  P  L16308134   PF  S19794970      Y  A31790128   NaN   NaN  10063630  MDR  LLT  10083228                         Genital scratch    3        N    NaN\n",
       "112384    11068335  C5244088  ENG  P  L16307902   PF  S19795037      Y  A31789368   NaN   NaN  10046713  MDR  LLT  10083293                           Indiana pouch    3        N    NaN\n",
       "\n",
       "[112385 rows x 19 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umls_eng_mdr = pd.read_csv('../../data/external/mrconso_umls/MRCONSO_ENG_MDR.csv')\n",
    "umls_eng_mdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CODE</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10000001</th>\n",
       "      <td>{\"Ventilation\" pneumonitis}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000002</th>\n",
       "      <td>{11-beta-hydroxylase deficiency}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000003</th>\n",
       "      <td>{11-oxysteroid activity incr}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000004</th>\n",
       "      <td>{11-oxysteroid activity increased}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000005</th>\n",
       "      <td>{17 ketosteroids urine}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000231</th>\n",
       "      <td>{Infective pneumonia (SMQ)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000232</th>\n",
       "      <td>{Dehydration (SMQ)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000233</th>\n",
       "      <td>{Hypokalaemia (SMQ), Hypokalemia (SMQ)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000234</th>\n",
       "      <td>{Sepsis (SMQ)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000235</th>\n",
       "      <td>{Opportunistic infections (SMQ)}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84213 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              STR\n",
       "CODE                                             \n",
       "10000001              {\"Ventilation\" pneumonitis}\n",
       "10000002         {11-beta-hydroxylase deficiency}\n",
       "10000003            {11-oxysteroid activity incr}\n",
       "10000004       {11-oxysteroid activity increased}\n",
       "10000005                  {17 ketosteroids urine}\n",
       "...                                           ...\n",
       "20000231              {Infective pneumonia (SMQ)}\n",
       "20000232                      {Dehydration (SMQ)}\n",
       "20000233  {Hypokalaemia (SMQ), Hypokalemia (SMQ)}\n",
       "20000234                           {Sepsis (SMQ)}\n",
       "20000235         {Opportunistic infections (SMQ)}\n",
       "\n",
       "[84213 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_to_term = umls_eng_mdr[['CODE', 'STR']].groupby('CODE').agg(set)\n",
    "code_to_term[[len(i)>1 for i in code_to_term['STR']]].to_numpy()\n",
    "code_to_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PsyTar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MDR_code_by_CUI(CUI):\n",
    "    potentials = umls_eng_mdr[umls_eng_mdr['CUI']==CUI]\n",
    "    lst =  potentials['CODE'].to_list()\n",
    "    return max(set(lst), key=lst.count) if len(lst) > 0 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "psytar_text = pd.read_excel('../../data/external/psytar/PsyTAR_dataset.xlsx', sheet_name='Sentence_Labeling')\n",
    "psytar_text = psytar_text[['drug_id', 'sentences']]\n",
    "psytar_text = psytar_text.groupby('drug_id').agg(list)\n",
    "psytar_text = psytar_text.reset_index(inplace=False)\n",
    "psytar_text['sentences'] = psytar_text['sentences'].apply(lambda x: '<SENT>'.join([str(i) for i in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "psytar_sent = pd.read_excel('../../data/external/psytar/PsyTAR_dataset.xlsx', sheet_name='ADR_Identified')\n",
    "psytar_adr = pd.read_excel('../../data/external/psytar/PsyTAR_dataset.xlsx', sheet_name='ADR_Mapped')\n",
    "\n",
    "# SENT\n",
    "psytar_sent['mention'] = psytar_sent.apply(\n",
    "    lambda x: [x[col] for col in psytar_sent if 'ADR' in col and x[col] is not np.nan], \n",
    "    axis=1)\n",
    "psytar_sent = psytar_sent[[col for col in psytar_sent.columns if \"ADR\" not in col]]\n",
    "psytar_sent = psytar_sent[['id', 'drug_id', 'sentence_index', 'sentences']]\n",
    "psytar_sent = psytar_sent.rename(columns={'sentences': 'sentence'})\n",
    "\n",
    "# ADR\n",
    "psytar_adr = psytar_adr[psytar_adr['type']=='ADR'][\n",
    "    ['drug_id', 'sentence_index', 'ADRs', 'UMLS1']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGE\n",
    "psytar = pd.merge(psytar_adr, psytar_sent,  how='left', \n",
    "         left_on=['drug_id','sentence_index'], \n",
    "         right_on = ['drug_id','sentence_index'])\n",
    "\n",
    "psytar = psytar.merge(psytar_text, on='drug_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaigorodov/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# get CUI and term positions (may be more)\n",
    "psytar['CUI'], psytar['term'] = zip(*psytar['UMLS1'].apply(lambda x: x.split('/')[:2] if len(x.split('/')) >= 2 else [x, None]))\n",
    "\n",
    "# drop bad data\n",
    "psytar = psytar[~psytar['term'].isna()]\n",
    "psytar = psytar[psytar['CUI'].str[0]=='C']\n",
    "\n",
    "# select needed columns\n",
    "psytar_adrs = psytar[['ADRs', 'term', 'CUI', 'sentence_index', 'sentence', 'sentences']]\n",
    "psytar_adrs['MDR'] = psytar_adrs['CUI'].apply(lambda x: get_MDR_code_by_CUI(x.strip()))\n",
    "\n",
    "psytar_adrs = psytar_adrs.drop(columns=['CUI'])\n",
    "psytar_adrs = psytar_adrs.dropna()\n",
    "psytar_adrs = psytar_adrs.rename(columns={\n",
    "    'term': 'norm_form',\n",
    "    'ADRs': 'term',\n",
    "    'sentence_index': 'sent_idx',\n",
    "    'sentence': 'sent',\n",
    "    'sentences': 'text',\n",
    "    'MDR': 'code'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sent_idx</th>\n",
       "      <th>text</th>\n",
       "      <th>norm_form</th>\n",
       "      <th>code</th>\n",
       "      <th>STR</th>\n",
       "      <th>SNMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>short-term memory loss</td>\n",
       "      <td>21.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>extreme weight gain, short-term memory loss, h...</td>\n",
       "      <td>Poor short-term memory</td>\n",
       "      <td>10040602.0</td>\n",
       "      <td>Short-term memory loss</td>\n",
       "      <td>['Poor short-term memory', 'Short-term memory ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hair loss</td>\n",
       "      <td>45.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>extreme weight gain, short-term memory loss, h...</td>\n",
       "      <td>Alopecia</td>\n",
       "      <td>10001760.0</td>\n",
       "      <td>Alopecia</td>\n",
       "      <td>['Alopecia', 'Alopecia', 'Alopecia', 'Alopecia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>completely destroyed sexually functioning</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "      <td>COMPLETELY DESTROYED SEXUALLY FUNCTIONING .&lt;SE...</td>\n",
       "      <td>Sexual Dysfunction</td>\n",
       "      <td>10040477.0</td>\n",
       "      <td>Sexual dysfunction</td>\n",
       "      <td>['Sexual dysfunction', 'Sexual dysfunction', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>completely destroyed my sexual functioning</td>\n",
       "      <td>144.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>4</td>\n",
       "      <td>COMPLETELY DESTROYED SEXUALLY FUNCTIONING .&lt;SE...</td>\n",
       "      <td>Sexual Dysfunction</td>\n",
       "      <td>10040477.0</td>\n",
       "      <td>Sexual dysfunction</td>\n",
       "      <td>['Sexual dysfunction', 'Sexual dysfunction', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pssd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>COMPLETELY DESTROYED SEXUALLY FUNCTIONING .&lt;SE...</td>\n",
       "      <td>Sexual Dysfunction</td>\n",
       "      <td>10040477.0</td>\n",
       "      <td>Sexual dysfunction</td>\n",
       "      <td>['Sexual dysfunction', 'Sexual dysfunction', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3985</th>\n",
       "      <td>early on: nausea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Stomach problems early on: bloating, nausea, c...</td>\n",
       "      <td>Nausea</td>\n",
       "      <td>10028813.0</td>\n",
       "      <td>Nausea</td>\n",
       "      <td>['Nausea', 'Nausea', 'Nausea', 'Nausea', 'Naus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3986</th>\n",
       "      <td>early on: constipation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Stomach problems early on: bloating, nausea, c...</td>\n",
       "      <td>Constipation</td>\n",
       "      <td>10010774.0</td>\n",
       "      <td>Constipation</td>\n",
       "      <td>['Constipation', 'Constipation', 'Constipation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3987</th>\n",
       "      <td>yawning</td>\n",
       "      <td>137.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Stomach problems early on: bloating, nausea, c...</td>\n",
       "      <td>Yawning</td>\n",
       "      <td>10048232.0</td>\n",
       "      <td>Yawning</td>\n",
       "      <td>['Yawning', 'Yawning', 'Yawn', '[D]Yawning', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3988</th>\n",
       "      <td>mild insomnia for the first 3 days</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>The only side effects I experienced were mild ...</td>\n",
       "      <td>Sleeplessness</td>\n",
       "      <td>10022437.0</td>\n",
       "      <td>Insomnia</td>\n",
       "      <td>['Sleeplessness', 'Sleeplessness', 'Sleeplessn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3989</th>\n",
       "      <td>extreme shakiness for the first 3 days</td>\n",
       "      <td>59.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>1</td>\n",
       "      <td>The only side effects I experienced were mild ...</td>\n",
       "      <td>Shakes</td>\n",
       "      <td>10040527.0</td>\n",
       "      <td>Shakiness</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3990 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            term  start    end  sent_idx                                               text                 norm_form        code                     STR                                               SNMS\n",
       "0                         short-term memory loss   21.0   43.0         1  extreme weight gain, short-term memory loss, h...   Poor short-term memory   10040602.0  Short-term memory loss  ['Poor short-term memory', 'Short-term memory ...\n",
       "1                                      hair loss   45.0   54.0         1  extreme weight gain, short-term memory loss, h...                 Alopecia   10001760.0                Alopecia  ['Alopecia', 'Alopecia', 'Alopecia', 'Alopecia...\n",
       "2      completely destroyed sexually functioning    0.0   41.0         1  COMPLETELY DESTROYED SEXUALLY FUNCTIONING .<SE...       Sexual Dysfunction   10040477.0      Sexual dysfunction  ['Sexual dysfunction', 'Sexual dysfunction', '...\n",
       "3     completely destroyed my sexual functioning  144.0  186.0         4  COMPLETELY DESTROYED SEXUALLY FUNCTIONING .<SE...       Sexual Dysfunction   10040477.0      Sexual dysfunction  ['Sexual dysfunction', 'Sexual dysfunction', '...\n",
       "4                                           pssd    NaN    NaN         5  COMPLETELY DESTROYED SEXUALLY FUNCTIONING .<SE...       Sexual Dysfunction   10040477.0      Sexual dysfunction  ['Sexual dysfunction', 'Sexual dysfunction', '...\n",
       "...                                          ...    ...    ...       ...                                                ...                       ...         ...                     ...                                                ...\n",
       "3985                            early on: nausea    NaN    NaN         1  Stomach problems early on: bloating, nausea, c...                   Nausea   10028813.0                  Nausea  ['Nausea', 'Nausea', 'Nausea', 'Nausea', 'Naus...\n",
       "3986                      early on: constipation    NaN    NaN         1  Stomach problems early on: bloating, nausea, c...             Constipation   10010774.0            Constipation  ['Constipation', 'Constipation', 'Constipation...\n",
       "3987                                     yawning  137.0  144.0         3  Stomach problems early on: bloating, nausea, c...                  Yawning   10048232.0                 Yawning  ['Yawning', 'Yawning', 'Yawn', '[D]Yawning', '...\n",
       "3988          mild insomnia for the first 3 days    NaN    NaN         1  The only side effects I experienced were mild ...            Sleeplessness   10022437.0                Insomnia  ['Sleeplessness', 'Sleeplessness', 'Sleeplessn...\n",
       "3989      extreme shakiness for the first 3 days   59.0   97.0         1  The only side effects I experienced were mild ...                   Shakes   10040527.0               Shakiness                                                 []\n",
       "\n",
       "[3990 rows x 9 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAKE SPANS\n",
    "psytar_adrs['span'] = psytar_adrs.apply(\n",
    "    lambda x: list(re.finditer(x['term'].lower(), x['text'].lower())), axis=1)\n",
    "\n",
    "psytar_adrs['start'] = psytar_adrs['span'].apply(lambda x: x[0].span()[0] if len(x) == 1 else None)\n",
    "psytar_adrs['end'] = psytar_adrs['span'].apply(lambda x: x[0].span()[1] if len(x) == 1 else None)\n",
    "\n",
    "psytar_adrs = psytar_adrs.drop(columns=['span'])\n",
    "psytar_adrs = psytar_adrs[\n",
    "    ['term', 'start', 'end', 'sent_idx', 'text', 'norm_form', 'code']\n",
    "]\n",
    "\n",
    "#psytar_adrs = psytar_adrs[psytar_adrs['code'].str.isdigit()]\n",
    "\n",
    "mdr_codes = pd.read_csv('../../data/interim/meddra_codes_terms_synonims.csv')\n",
    "mdr_cod_to_norm = mdr_codes[['CODE', 'STR', 'SNMS']]\n",
    "psytar_adrs = pd.merge(psytar_adrs, mdr_cod_to_norm, left_on='code', right_on='CODE', how='left')\n",
    "psytar_adrs = psytar_adrs.drop(columns=['CODE'])\n",
    "psytar_adrs\n",
    "\n",
    "psytar_adrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "psytar_adrs_train, psytar_adrs_test = train_test_split(psytar_adrs, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaigorodov/.local/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/kaigorodov/.local/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " 15%|█▍        | 300/2023 [00:00<00:00, 2996.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (2023, 9) / test: (798, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2023/2023 [00:00<00:00, 3053.05it/s]\n",
      "  0%|          | 2/2023 [00:00<01:42, 19.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented textaugment wdnt: (4046, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2023/2023 [03:26<00:00,  9.81it/s]\n",
      "  0%|          | 2/2023 [00:00<01:42, 19.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented nlpaug wdnt: (4046, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2023/2023 [03:26<00:00,  9.80it/s]\n",
      " 37%|███▋      | 207/562 [00:00<00:00, 2069.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented nlpaug ppdb: (4046, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:00<00:00, 2158.43it/s]\n",
      "100%|██████████| 562/562 [00:00<00:00, 2168.94it/s]\n",
      "100%|██████████| 562/562 [00:00<00:00, 2311.76it/s]\n",
      "100%|██████████| 562/562 [00:00<00:00, 2329.54it/s]\n",
      "100%|██████████| 562/562 [00:00<00:00, 2286.39it/s]\n",
      " 35%|███▌      | 199/562 [00:00<00:00, 1986.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented textaugment wdnt repl 2: (2498, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 562/562 [00:00<00:00, 1957.97it/s]\n",
      "100%|██████████| 562/562 [00:00<00:00, 2004.39it/s]\n",
      "100%|██████████| 562/562 [00:00<00:00, 2053.79it/s]\n",
      "100%|██████████| 562/562 [00:00<00:00, 2061.61it/s]\n",
      "100%|██████████| 562/562 [00:00<00:00, 2138.73it/s]\n",
      "100%|██████████| 562/562 [00:00<00:00, 9019.53it/s]\n",
      "100%|██████████| 562/562 [00:00<00:00, 12834.09it/s]\n",
      "  0%|          | 0/2585 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented textaugment wdnt repl 3: (2507, 2)\n",
      "train augmented textaugment wdnt insrt: (2560, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2585/2585 [00:00<00:00, 69168.34it/s]\n",
      "100%|██████████| 2023/2023 [00:00<00:00, 80011.66it/s]\n",
      "100%|██████████| 2023/2023 [00:00<00:00, 70914.63it/s]\n",
      "  0%|          | 0/2023 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented textaugment wdnt insrt CONCEPT_RETRO: (2407, 2)\n",
      "train concept: (2303, 2)\n",
      "train concept retro: (2407, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2023/2023 [00:00<00:00, 42757.40it/s]\n",
      "100%|██████████| 2023/2023 [00:00<00:00, 68113.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train all internal: (2420, 2)\n",
      "train big: (83771, 2)\n"
     ]
    }
   ],
   "source": [
    "get_ready_data(psytar_adrs_train, psytar_adrs_test, 'psytar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(630,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_used_codes_psytar = np.concatenate([psytar_adrs_train['code'].unique(), psytar_adrs_test['code'].unique()])\n",
    "all_used_codes_psytar.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CADEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "empty_files = 0\n",
    "for file in os.listdir('../../data/external/cadec2/cadec/meddra/'):\n",
    "    try:\n",
    "        file_name = '.'.join(file.split('.')[:2])\n",
    "        #print(file_name)\n",
    "        text = pd.read_csv('../../data/external/cadec2/cadec/text/' + f\"{file_name}.txt\", sep='\\t', header=None)\n",
    "        adr = pd.read_csv('../../data/external/cadec2/cadec/meddra/' + file, sep='\\t', header=None)\n",
    "\n",
    "    except pd.errors.EmptyDataError as e:\n",
    "        empty_files += 1\n",
    "        #print(file, end=' ')\n",
    "        continue\n",
    "    \n",
    "    # подбор предложения\n",
    "    adr['sent_number'] = adr[0].apply(lambda x: int(x[2:])-1 if x[2:].isdigit() else None)\n",
    "    text = text.reset_index()\n",
    "    df = pd.merge(adr, text, how='left', left_on='sent_number', right_on='index')\n",
    "    df['text'] = '<SENT>'.join(text[0].to_list())\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sent</th>\n",
       "      <th>text</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>light nausea</td>\n",
       "      <td>126</td>\n",
       "      <td>138</td>\n",
       "      <td>For the first 8 days of ever taking it, the on...</td>\n",
       "      <td>For the first 8 days of ever taking it, the on...</td>\n",
       "      <td>10028813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sharp pain in my stomach</td>\n",
       "      <td>229</td>\n",
       "      <td>253</td>\n",
       "      <td>After 8 days, the feeling elevated to an annoy...</td>\n",
       "      <td>For the first 8 days of ever taking it, the on...</td>\n",
       "      <td>10033371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pain unbearable</td>\n",
       "      <td>329</td>\n",
       "      <td>339</td>\n",
       "      <td>Then two days later, I had to stop using it be...</td>\n",
       "      <td>For the first 8 days of ever taking it, the on...</td>\n",
       "      <td>10033371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stomach pain</td>\n",
       "      <td>395</td>\n",
       "      <td>407</td>\n",
       "      <td>Now I have been off for two days and I still h...</td>\n",
       "      <td>For the first 8 days of ever taking it, the on...</td>\n",
       "      <td>10042076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stomach pain</td>\n",
       "      <td>424</td>\n",
       "      <td>436</td>\n",
       "      <td>Now I have to see my doctor again to see if I ...</td>\n",
       "      <td>For the first 8 days of ever taking it, the on...</td>\n",
       "      <td>10042076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>pain in back</td>\n",
       "      <td>366</td>\n",
       "      <td>370</td>\n",
       "      <td>I lost 2 months of my life and I still don't r...</td>\n",
       "      <td>Horrific medication - Suffered an acute pancre...</td>\n",
       "      <td>10003993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sedation</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>Mild sedation.</td>\n",
       "      <td>Mild sedation.&lt;SENT&gt;This is a GREAT drug for m...</td>\n",
       "      <td>10039897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nausea</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>nausea.</td>\n",
       "      <td>nausea.&lt;SENT&gt;some pain relief.</td>\n",
       "      <td>10028813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hurts throat</td>\n",
       "      <td>111</td>\n",
       "      <td>116</td>\n",
       "      <td>My throat still hurts while on it; however the...</td>\n",
       "      <td>Haven't really experienced any side effects th...</td>\n",
       "      <td>10033494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stiff neck</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>stiff neck, tightness in shoulders, muscle pain.</td>\n",
       "      <td>stiff neck, tightness in shoulders, muscle pai...</td>\n",
       "      <td>10042043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4401 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        term start  end                                               sent                                               text      code\n",
       "0               light nausea   126  138  For the first 8 days of ever taking it, the on...  For the first 8 days of ever taking it, the on...  10028813\n",
       "1   sharp pain in my stomach   229  253  After 8 days, the feeling elevated to an annoy...  For the first 8 days of ever taking it, the on...  10033371\n",
       "2            pain unbearable   329  339  Then two days later, I had to stop using it be...  For the first 8 days of ever taking it, the on...  10033371\n",
       "3               stomach pain   395  407  Now I have been off for two days and I still h...  For the first 8 days of ever taking it, the on...  10042076\n",
       "4               stomach pain   424  436  Now I have to see my doctor again to see if I ...  For the first 8 days of ever taking it, the on...  10042076\n",
       "..                       ...   ...  ...                                                ...                                                ...       ...\n",
       "12              pain in back   366  370  I lost 2 months of my life and I still don't r...  Horrific medication - Suffered an acute pancre...  10003993\n",
       "0                   sedation     5   13                                     Mild sedation.  Mild sedation.<SENT>This is a GREAT drug for m...  10039897\n",
       "0                     nausea     0    6                                            nausea.                     nausea.<SENT>some pain relief.  10028813\n",
       "0               hurts throat   111  116  My throat still hurts while on it; however the...  Haven't really experienced any side effects th...  10033494\n",
       "0                 stiff neck     0   10   stiff neck, tightness in shoulders, muscle pain.  stiff neck, tightness in shoulders, muscle pai...  10042043\n",
       "\n",
       "[4401 rows x 6 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cadec2 = pd.concat(dfs, axis=0)\n",
    "\n",
    "cadec2 = cadec2.rename(\n",
    "    columns={1: 'code_span', 2: 'term', '0_y': 'sent'})[['term', 'code_span', 'sent', 'text']]\n",
    "\n",
    "cadec2 = cadec2.dropna()\n",
    "\n",
    "cadec2['code'] = cadec2['code_span'].apply(lambda x: x.split(' ')[0])\n",
    "cadec2['span'] = cadec2['code_span'].apply(lambda x: x.split(' ')[-2:])\n",
    "cadec2['span'] = cadec2['span'].apply(lambda x: [i.split(';')[-1] for i in x])\n",
    "\n",
    "cadec2 = cadec2[cadec2['code'].str.isdigit()]\n",
    "cadec2['start'] = cadec2['span'].apply(lambda x: x[0])\n",
    "cadec2['end'] = cadec2['span'].apply(lambda x: x[1])\n",
    "\n",
    "cadec2 = cadec2[\n",
    "    ['term', 'start', 'end', 'sent', 'text', 'code']\n",
    "]\n",
    "\n",
    "cadec2 = cadec2[cadec2['code'].str.isdigit()]\n",
    "cadec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cadec2['code'] = cadec2['code'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>sent</th>\n",
       "      <th>text</th>\n",
       "      <th>code</th>\n",
       "      <th>STR</th>\n",
       "      <th>SNMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>light nausea</td>\n",
       "      <td>126</td>\n",
       "      <td>138</td>\n",
       "      <td>For the first 8 days of ever taking it, the on...</td>\n",
       "      <td>For the first 8 days of ever taking it, the on...</td>\n",
       "      <td>10028813</td>\n",
       "      <td>Nausea</td>\n",
       "      <td>['Nausea', 'Nausea', 'Nausea', 'Nausea', 'Naus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sharp pain in my stomach</td>\n",
       "      <td>229</td>\n",
       "      <td>253</td>\n",
       "      <td>After 8 days, the feeling elevated to an annoy...</td>\n",
       "      <td>For the first 8 days of ever taking it, the on...</td>\n",
       "      <td>10033371</td>\n",
       "      <td>Pain</td>\n",
       "      <td>['Pain', 'Pain', 'Pain', 'Pain', 'Pain', 'Pain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pain unbearable</td>\n",
       "      <td>329</td>\n",
       "      <td>339</td>\n",
       "      <td>Then two days later, I had to stop using it be...</td>\n",
       "      <td>For the first 8 days of ever taking it, the on...</td>\n",
       "      <td>10033371</td>\n",
       "      <td>Pain</td>\n",
       "      <td>['Pain', 'Pain', 'Pain', 'Pain', 'Pain', 'Pain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stomach pain</td>\n",
       "      <td>395</td>\n",
       "      <td>407</td>\n",
       "      <td>Now I have been off for two days and I still h...</td>\n",
       "      <td>For the first 8 days of ever taking it, the on...</td>\n",
       "      <td>10042076</td>\n",
       "      <td>Stomach ache</td>\n",
       "      <td>['Stomach ache', 'Stomach ache', 'Belly ache',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>stomach pain</td>\n",
       "      <td>424</td>\n",
       "      <td>436</td>\n",
       "      <td>Now I have to see my doctor again to see if I ...</td>\n",
       "      <td>For the first 8 days of ever taking it, the on...</td>\n",
       "      <td>10042076</td>\n",
       "      <td>Stomach ache</td>\n",
       "      <td>['Stomach ache', 'Stomach ache', 'Belly ache',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4396</th>\n",
       "      <td>pain in back</td>\n",
       "      <td>366</td>\n",
       "      <td>370</td>\n",
       "      <td>I lost 2 months of my life and I still don't r...</td>\n",
       "      <td>Horrific medication - Suffered an acute pancre...</td>\n",
       "      <td>10003993</td>\n",
       "      <td>Backache</td>\n",
       "      <td>['Back pain', 'Back pain', 'Back pain', 'Back ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4397</th>\n",
       "      <td>sedation</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>Mild sedation.</td>\n",
       "      <td>Mild sedation.&lt;SENT&gt;This is a GREAT drug for m...</td>\n",
       "      <td>10039897</td>\n",
       "      <td>Sedation</td>\n",
       "      <td>['Sedated state', 'Sedated', 'Under sedation',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4398</th>\n",
       "      <td>nausea</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>nausea.</td>\n",
       "      <td>nausea.&lt;SENT&gt;some pain relief.</td>\n",
       "      <td>10028813</td>\n",
       "      <td>Nausea</td>\n",
       "      <td>['Nausea', 'Nausea', 'Nausea', 'Nausea', 'Naus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4399</th>\n",
       "      <td>hurts throat</td>\n",
       "      <td>111</td>\n",
       "      <td>116</td>\n",
       "      <td>My throat still hurts while on it; however the...</td>\n",
       "      <td>Haven't really experienced any side effects th...</td>\n",
       "      <td>10033494</td>\n",
       "      <td>Pain throat</td>\n",
       "      <td>['Sore throat', 'Sore throat', 'Sore throat', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4400</th>\n",
       "      <td>stiff neck</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>stiff neck, tightness in shoulders, muscle pain.</td>\n",
       "      <td>stiff neck, tightness in shoulders, muscle pai...</td>\n",
       "      <td>10042043</td>\n",
       "      <td>Stiff neck</td>\n",
       "      <td>['Neck stiffness', 'Neck stiffness', 'Neck rig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4401 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          term start  end                                               sent                                               text      code           STR                                               SNMS\n",
       "0                 light nausea   126  138  For the first 8 days of ever taking it, the on...  For the first 8 days of ever taking it, the on...  10028813        Nausea  ['Nausea', 'Nausea', 'Nausea', 'Nausea', 'Naus...\n",
       "1     sharp pain in my stomach   229  253  After 8 days, the feeling elevated to an annoy...  For the first 8 days of ever taking it, the on...  10033371          Pain  ['Pain', 'Pain', 'Pain', 'Pain', 'Pain', 'Pain...\n",
       "2              pain unbearable   329  339  Then two days later, I had to stop using it be...  For the first 8 days of ever taking it, the on...  10033371          Pain  ['Pain', 'Pain', 'Pain', 'Pain', 'Pain', 'Pain...\n",
       "3                 stomach pain   395  407  Now I have been off for two days and I still h...  For the first 8 days of ever taking it, the on...  10042076  Stomach ache  ['Stomach ache', 'Stomach ache', 'Belly ache',...\n",
       "4                 stomach pain   424  436  Now I have to see my doctor again to see if I ...  For the first 8 days of ever taking it, the on...  10042076  Stomach ache  ['Stomach ache', 'Stomach ache', 'Belly ache',...\n",
       "...                        ...   ...  ...                                                ...                                                ...       ...           ...                                                ...\n",
       "4396              pain in back   366  370  I lost 2 months of my life and I still don't r...  Horrific medication - Suffered an acute pancre...  10003993      Backache  ['Back pain', 'Back pain', 'Back pain', 'Back ...\n",
       "4397                  sedation     5   13                                     Mild sedation.  Mild sedation.<SENT>This is a GREAT drug for m...  10039897      Sedation  ['Sedated state', 'Sedated', 'Under sedation',...\n",
       "4398                    nausea     0    6                                            nausea.                     nausea.<SENT>some pain relief.  10028813        Nausea  ['Nausea', 'Nausea', 'Nausea', 'Nausea', 'Naus...\n",
       "4399              hurts throat   111  116  My throat still hurts while on it; however the...  Haven't really experienced any side effects th...  10033494   Pain throat  ['Sore throat', 'Sore throat', 'Sore throat', ...\n",
       "4400                stiff neck     0   10   stiff neck, tightness in shoulders, muscle pain.  stiff neck, tightness in shoulders, muscle pai...  10042043    Stiff neck  ['Neck stiffness', 'Neck stiffness', 'Neck rig...\n",
       "\n",
       "[4401 rows x 8 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdr_codes = pd.read_csv('../../data/interim/meddra_codes_terms_synonims.csv')\n",
    "mdr_cod_to_norm = mdr_codes[['CODE', 'STR', 'SNMS']]\n",
    "cadec2 = pd.merge(cadec2, mdr_cod_to_norm, left_on='code', right_on='CODE', how='left')\n",
    "cadec2 = cadec2.drop(columns=['CODE'])\n",
    "cadec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cadec2_train, cadec2_test = train_test_split(cadec2, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kaigorodov/.local/lib/python3.6/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "/home/kaigorodov/.local/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " 17%|█▋        | 338/1981 [00:00<00:00, 3376.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (1981, 8) / test: (881, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1981/1981 [00:00<00:00, 3279.10it/s]\n",
      "  0%|          | 2/1981 [00:00<01:41, 19.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented textaugment wdnt: (3962, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1981/1981 [03:22<00:00,  9.80it/s]\n",
      "  0%|          | 2/1981 [00:00<01:40, 19.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented nlpaug wdnt: (3962, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1981/1981 [03:22<00:00,  9.81it/s]\n",
      " 29%|██▉       | 223/757 [00:00<00:00, 2228.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented nlpaug ppdb: (3962, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 757/757 [00:00<00:00, 2183.59it/s]\n",
      "100%|██████████| 757/757 [00:00<00:00, 2321.19it/s]\n",
      "100%|██████████| 757/757 [00:00<00:00, 2405.33it/s]\n",
      "100%|██████████| 757/757 [00:00<00:00, 2424.55it/s]\n",
      "100%|██████████| 757/757 [00:00<00:00, 2485.37it/s]\n",
      " 30%|██▉       | 224/757 [00:00<00:00, 2232.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented textaugment wdnt repl 2: (2600, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 757/757 [00:00<00:00, 2086.16it/s]\n",
      "100%|██████████| 757/757 [00:00<00:00, 2091.92it/s]\n",
      "100%|██████████| 757/757 [00:00<00:00, 2116.72it/s]\n",
      "100%|██████████| 757/757 [00:00<00:00, 2157.35it/s]\n",
      "100%|██████████| 757/757 [00:00<00:00, 2190.70it/s]\n",
      "100%|██████████| 757/757 [00:00<00:00, 9537.35it/s]\n",
      "100%|██████████| 757/757 [00:00<00:00, 13521.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented textaugment wdnt repl 3: (2608, 2)\n",
      "train augmented textaugment wdnt insrt: (2699, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2738/2738 [00:00<00:00, 69161.17it/s]\n",
      "100%|██████████| 1981/1981 [00:00<00:00, 78059.77it/s]\n",
      "100%|██████████| 1981/1981 [00:00<00:00, 71128.85it/s]\n",
      "  0%|          | 0/1981 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train augmented textaugment wdnt insrt CONCEPT_RETRO: (2478, 2)\n",
      "train concept: (2326, 2)\n",
      "train concept retro: (2478, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1981/1981 [00:00<00:00, 42354.18it/s]\n",
      "100%|██████████| 1981/1981 [00:00<00:00, 70260.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train all internal: (3342, 2)\n",
      "train big: (84600, 2)\n"
     ]
    }
   ],
   "source": [
    "get_ready_data(cadec2_train, cadec2_test, 'cadec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(787,)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_used_codes_cadec = np.concatenate([cadec2_train['code'].unique(), cadec2_test['code'].unique()])\n",
    "all_used_codes_cadec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRCONSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrconso = pd.read_csv('../../data/external/mrconso_umls/MRCONSO_ENG.RRF', sep='|', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrconso = mrconso.rename(columns={\n",
    "    0: \"CUI\", \n",
    "    1: 'LAT',\n",
    "    2: 'TS',\n",
    "    3: \"LUI\",\n",
    "    4: \"STT\",\n",
    "    5: \"SUI\",\n",
    "    6: \"ISPREF\",\n",
    "    7: \"AUI\",\n",
    "    8: \"SAUI\",\n",
    "    9: \"SCUI\",\n",
    "    10: \"SDUI\",\n",
    "    11: \"SAB\",\n",
    "    12: \"TTY\",\n",
    "    13: \"CODE\",\n",
    "    14: \"STR\",\n",
    "    15: \"SRL\",\n",
    "    16: \"SUPPRESS\",\n",
    "    17: \"CVF\"\n",
    "})[\n",
    "    [\"CUI\", \"TS\", \"SAB\", \"TTY\", \"CODE\", \"STR\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdr_codes = mrconso[mrconso['SAB']==\"MDR\"].groupby(\"CODE\").agg(lambda x: x.unique())\n",
    "snomed =    mrconso[mrconso['SAB']==\"SNOMEDCT_US\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdr_codes = mdr_codes.reset_index(inplace=False)\n",
    "mdr_codes['SNMS'] = mdr_codes['CUI'].progress_apply(lambda cui: snomed[snomed['CUI']==cui]['STR'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdr_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdr_codes.to_csv('../../data/interim/meddra_codes_terms_synonims.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2['code']==10013767]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['code']==10013767]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[0, 'SNMS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[0, 'SNMS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
