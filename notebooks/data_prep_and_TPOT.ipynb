{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import copy\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pymedtermino\n",
    "import seaborn as sns\n",
    "\n",
    "from metric_learn import NCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level = logging.DEBUG, filename = \"TPOT_examples.log\")\n",
    "logging.debug(\"debug\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "generations = 2\n",
    "population_size = 50\n",
    "max_eval_time_mins = 2\n",
    "n_jobs = 10\n",
    "max_iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "X, y = make_classification(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=0)\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('svc', SVC())])\n",
    "# The pipeline can be used as any other estimator\n",
    "# and avoids leaking the test set into the train set\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe['svc'].get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/interim/meddra_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_huge = pd.read_csv('../data/interim/terms_and_codes.csv')\n",
    "df_huge = df_huge[['term', 'code']].rename(columns={'term': 'text', 'code': 'meddra'})\n",
    "df_huge['meddra'] = df_huge['meddra'].apply(lambda x: int(x) if x.isdigit() else None)\n",
    "df_huge = df_huge[df_huge['meddra'].isin(df['meddra'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('../data/interim/simple_data.csv', index=False)\n",
    "# df_huge.to_csv('../data/interim/rich_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>meddra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can't go out in the sun</td>\n",
       "      <td>10034972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>waking up after the longest dream</td>\n",
       "      <td>10041349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eventful movie night in your dreams</td>\n",
       "      <td>10000125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>may NOT switch your brain off</td>\n",
       "      <td>10064805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sleep for the next 2 days</td>\n",
       "      <td>10020765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2687</th>\n",
       "      <td>flaring</td>\n",
       "      <td>10010264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2688</th>\n",
       "      <td>flares</td>\n",
       "      <td>10010264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2689</th>\n",
       "      <td>flare</td>\n",
       "      <td>10010264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2690</th>\n",
       "      <td>fistulas</td>\n",
       "      <td>10016717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>-9.5lbs</td>\n",
       "      <td>10047895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2692 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     text    meddra\n",
       "0                 can't go out in the sun  10034972\n",
       "1       waking up after the longest dream  10041349\n",
       "2     eventful movie night in your dreams  10000125\n",
       "3           may NOT switch your brain off  10064805\n",
       "4               sleep for the next 2 days  10020765\n",
       "...                                   ...       ...\n",
       "2687                              flaring  10010264\n",
       "2688                               flares  10010264\n",
       "2689                                flare  10010264\n",
       "2690                             fistulas  10016717\n",
       "2691                              -9.5lbs  10047895\n",
       "\n",
       "[2692 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pure meddra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2153, 7), (2153,), (539, 7), (539,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/interim/meddra_data.csv')\n",
    "meddra_labels = {v:k for k, v in enumerate(df['meddra'].unique())}\n",
    "df['meddra_label'] = df['meddra'].apply(lambda x: int(meddra_labels[x]))\n",
    "train, test = train_test_split(df, test_size=0.20)\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train['text'])\n",
    "\n",
    "train['text_tokenized'] = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(train['text']), maxlen=7).tolist()\n",
    "test['text_tokenized'] = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(test['text']), maxlen=7).tolist()\n",
    "train['counts'] = train['meddra_label'].apply(lambda x: train[train['meddra_label']==x].shape[0])\n",
    "#train = train[train['counts']>50]\n",
    "\n",
    "X_train = np.array(train['text_tokenized'].to_list())\n",
    "y_train = np.array(train['meddra_label'].to_list())\n",
    "\n",
    "X_test = np.array(test['text_tokenized'].to_list())\n",
    "y_test = np.array(test['meddra_label'].to_list())\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 51,  54,   5, 306,  17,  57,  62, 143, 163, 181,   5, 102, 372,\n",
       "       144,  20, 145,  20,  34, 120,  57, 205,  39,  24,  40,  10,   2,\n",
       "       102, 276, 124, 245,   5, 379, 371,   2,   5, 189,  16, 175,  40,\n",
       "        69, 230,   5,  37, 154,   5, 183, 165,   4,  88, 379,  52, 129,\n",
       "         4,  68,   5, 162,  18, 122,  25, 456, 299, 358, 141,  24, 368,\n",
       "       264,   2,   5,  80, 202,  67,   4, 152,   5,  67,  95, 143,   2,\n",
       "        91,   5, 159,  40,   5,  64, 132,  40,   4,  24, 106,  68, 411,\n",
       "       121,  33,  40,  41,  57,  73, 107, 163,  65,   4,   5, 251,  24,\n",
       "         4,  61, 164, 300,   2,   5,  24,  35,  20,  16,   5,   4,   4,\n",
       "       124,  78,  95,  20,  16, 450,   1, 358,  40,  40,  97,  27,   5,\n",
       "        71,  82, 104,  24, 282,  40,   5,   1,   1, 172,  12,  40,   4,\n",
       "        28,   1,  68,   5,  24, 185, 221,  33,   5, 439, 184,  92,  54,\n",
       "        68, 233, 297,  82, 282, 233,  33,   0,   5,   4, 132,  36,   1,\n",
       "         5,  40,   5,   5,   4, 161,  40,  11,   5,  68,  22, 448, 171,\n",
       "        51, 139, 353, 216, 150,  14,  87, 356,   2,   8, 321,   5,   5,\n",
       "       346,  85, 406, 229,   8,  31, 463, 182, 221,  17,  59,   2,  26,\n",
       "         5, 138,  33, 302,  42,   5,  81,  20, 140,  29, 221, 393, 335,\n",
       "         1,   5,  80, 221, 342, 276,  24, 384,   5,  37, 150, 311, 184,\n",
       "        57,   1,  50,   5, 384, 101,   1,  68, 381, 148,  42,   4, 363,\n",
       "        95, 443, 436,   5,  90, 320,   4,   5, 148,  49, 102,   2, 113,\n",
       "       285, 114, 185, 239,  28, 144,  24,  85, 204, 298,  82,  58,   5,\n",
       "       267, 389,  20,   4,   4,  59, 260, 200,   5, 222,   2,   5, 370,\n",
       "        92,  20,  68,  76,   4,  98,   4,  24,  37, 301,  37,  11,  22,\n",
       "       295,  28,  69, 307,   1,  17,  50,   7,  34,  94, 221, 117, 116,\n",
       "        16,   4, 444,   1, 221,  64, 253, 120,   7,   5,   5,   2, 377,\n",
       "       224,  24, 367,  21, 210, 123,  87,  78, 215, 400,  74, 162,  68,\n",
       "       210,  72,  40,  12,  37,  30, 215,  83,  78,  40,   5, 267, 343,\n",
       "         5,  37,   1,   5,   5,  92,  29,  24, 171, 296,  65,  40,  16,\n",
       "        87,   2,  68,   4,  62, 279, 197,   5,   4, 395,  22, 209, 252,\n",
       "       273, 226,  37, 213, 150,  81,   1,   5, 138, 200, 134, 361, 239,\n",
       "       209,   2,  83, 164,  12,  31,   5,  27, 211,  24,   2,  28,   2,\n",
       "       190,  28, 239,   2, 183,  49,  78,   2, 229,  17, 445,  42,   5,\n",
       "         4,  69, 254,  62,   5,   5,  29, 104,  44,  37, 261,  16,  55,\n",
       "       291, 139, 267,  26,  78, 166, 430, 183, 155,  40,  65, 153,  75,\n",
       "        81,   5, 151,  69, 321,   4, 200,   2, 273,   5, 222,  95,  80,\n",
       "        75,  28,   4, 158,   4,  58, 378,  28,  78, 330,  18, 311,  20,\n",
       "        75, 265,   5,  81,   5,   5,  82,  42,  65, 110,   5, 135, 104,\n",
       "       167,  27, 127,   7,   5, 238,   1, 199, 208, 188,   2,  12,   4,\n",
       "        28, 307,  40,  86, 139, 144, 183,  69,  68,  73,  65,  37,   4,\n",
       "       257, 264, 291,   4,   5, 295,   4,   5, 327,  34,  24, 168, 277,\n",
       "         2,  42, 336, 240, 229, 187, 329,  22,   1,   2,   5,  78,  95,\n",
       "         4, 221,  77, 202,   0,   5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_data = (X_train, X_test, y_train, y_test)\n",
    "with open('../data/processed/pure_data.pkl', 'wb') as data_file:\n",
    "    pickle.dump(pure_data, data_file, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/150 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.23549020665839313\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.23549020665839313\n",
      "\n",
      "Best pipeline: ExtraTreesClassifier(input_matrix, bootstrap=False, criterion=gini, max_features=0.9000000000000001, min_samples_leaf=1, min_samples_split=17, n_estimators=100)\n"
     ]
    }
   ],
   "source": [
    "tpot = TPOTClassifier(generations=generations, \n",
    "                      population_size=population_size,\n",
    "                      verbosity=2, \n",
    "                      random_state=42, \n",
    "                      max_eval_time_mins=max_eval_time_mins, \n",
    "                      n_jobs=n_jobs)\n",
    "\n",
    "tpot.fit(X_train, y_train)\n",
    "score = tpot.score(X_test, y_test)\n",
    "logging.debug(f'PURE MEDDRA: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pure data with NCA (metric learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/150 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.13793773269303405\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.1388690444072735\n",
      "\n",
      "Best pipeline: KNeighborsClassifier(input_matrix, n_neighbors=73, p=1, weights=distance)\n"
     ]
    }
   ],
   "source": [
    "tpot = TPOTClassifier(generations=generations, \n",
    "                      population_size=population_size,\n",
    "                      verbosity=2, \n",
    "                      random_state=42, \n",
    "                      max_eval_time_mins=max_eval_time_mins, \n",
    "                      n_jobs=n_jobs)\n",
    "clf = make_pipeline(NCA(max_iter=max_iter), tpot)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "score = tpot.score(X_test, y_test)\n",
    "logging.debug(f'PURE MEDDRA with NCA: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pure vectorized data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2153, 768), (2153,), (539, 768), (539,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/interim/meddra_data_simple_vec.csv')\n",
    "meddra_labels = {v:k for k, v in enumerate(df['meddra'].unique())}\n",
    "df['meddra_label'] = df['meddra'].apply(lambda x: int(meddra_labels[x]))\n",
    "df = df.drop(columns=['text', 'meddra'])\n",
    "train, test = train_test_split(df, test_size=0.20)\n",
    "\n",
    "\n",
    "X_train = np.array(train[[col for col in df.columns if col != 'meddra_label']])\n",
    "y_train = np.array(train['meddra_label'].to_list())\n",
    "\n",
    "X_test = np.array(test[[col for col in df.columns if col != 'meddra_label']])\n",
    "y_test = np.array(test['meddra_label'].to_list())\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_data = (X_train, X_test, y_train, y_test)\n",
    "with open('../data/processed/pure_data_vectorized.pkl', 'wb') as data_file:\n",
    "    pickle.dump(rich_data, data_file, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/150 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.2972557060378784\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.2972557060378784\n",
      "\n",
      "Best pipeline: KNeighborsClassifier(input_matrix, n_neighbors=3, p=1, weights=distance)\n"
     ]
    }
   ],
   "source": [
    "tpot = TPOTClassifier(generations=generations, \n",
    "                      population_size=population_size,\n",
    "                      verbosity=2, \n",
    "                      random_state=42, \n",
    "                      max_eval_time_mins=max_eval_time_mins, \n",
    "                      n_jobs=n_jobs)\n",
    "\n",
    "tpot.fit(X_train, y_train)\n",
    "score = tpot.score(X_test, y_test)\n",
    "logging.debug(f'PURE MEDDRA vectorized: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pure vec data with NCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/150 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.38736200291372147\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.3901505422759402\n",
      "\n",
      "Best pipeline: KNeighborsClassifier(input_matrix, n_neighbors=2, p=2, weights=distance)\n"
     ]
    }
   ],
   "source": [
    "tpot = TPOTClassifier(generations=generations, \n",
    "                      population_size=population_size,\n",
    "                      verbosity=2, \n",
    "                      random_state=42, \n",
    "                      max_eval_time_mins=max_eval_time_mins, \n",
    "                      n_jobs=n_jobs)\n",
    "\n",
    "clf = make_pipeline(NCA(max_iter=max_iter), tpot)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "score = tpot.score(X_test, y_test)\n",
    "logging.debug(f'PURE MEDDRA vectorized with NCA: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enriched train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5166, 7), (5166,), (1292, 7), (1292,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/interim/rich_data.csv')\n",
    "meddra_labels = {v:k for k, v in enumerate(df['meddra'].unique())}\n",
    "df['meddra_label'] = df['meddra'].apply(lambda x: int(meddra_labels[x]))\n",
    "train, test = train_test_split(df, test_size=0.20)\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train['text'])\n",
    "\n",
    "train['text_tokenized'] = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(train['text']), maxlen=7).tolist()\n",
    "test['text_tokenized'] = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(test['text']), maxlen=7).tolist()\n",
    "train['counts'] = train['meddra_label'].apply(lambda x: train[train['meddra_label']==x].shape[0])\n",
    "#train = train[train['counts']>50]\n",
    "\n",
    "X_train = np.array(train['text_tokenized'].to_list())\n",
    "y_train = np.array(train['meddra_label'].to_list())\n",
    "\n",
    "X_test = np.array(test['text_tokenized'].to_list())\n",
    "y_test = np.array(test['meddra_label'].to_list())\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/150 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.3186225918013111\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.3778544023997259\n",
      "\n",
      "Best pipeline: KNeighborsClassifier(SelectFromModel(input_matrix, criterion=entropy, max_features=0.2, n_estimators=100, threshold=0.30000000000000004), n_neighbors=87, p=2, weights=distance)\n"
     ]
    }
   ],
   "source": [
    "tpot = TPOTClassifier(generations=generations,\n",
    "                      population_size=population_size,\n",
    "                      verbosity=2, \n",
    "                      random_state=42, \n",
    "                      max_eval_time_mins=max_eval_time_mins, \n",
    "                      n_jobs=n_jobs)\n",
    "tpot.fit(X_train, y_train)\n",
    "score = tpot.score(X_test, y_test)\n",
    "logging.debug(f'ENRICHED MEDDRA: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrich data with NCA (metric learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/150 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: 0.19067147760274575\n",
      "\n",
      "Generation 2 - Current best internal CV score: 0.19493054164224685\n",
      "\n",
      "Best pipeline: KNeighborsClassifier(input_matrix, n_neighbors=47, p=2, weights=distance)\n"
     ]
    }
   ],
   "source": [
    "tpot = TPOTClassifier(generations=generations, \n",
    "                      population_size=population_size,\n",
    "                      verbosity=2, \n",
    "                      random_state=42, \n",
    "                      max_eval_time_mins=max_eval_time_mins, \n",
    "                      n_jobs=n_jobs)\n",
    "clf = make_pipeline(NCA(max_iter=max_iter), tpot)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "score = tpot.score(X_test, y_test)\n",
    "logging.debug(f'ENRICHED MEDDRA with NCA: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrich data vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7320, 7), (7320,), (1830, 7), (1830,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/interim/meddra_data_rich_vec.csv')\n",
    "meddra_labels = {v:k for k, v in enumerate(df['meddra'].unique())}\n",
    "df['meddra_label'] = df['meddra'].apply(lambda x: int(meddra_labels[x]))\n",
    "train, test = train_test_split(df, test_size=0.20)\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=5000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(train['text'])\n",
    "\n",
    "train['text_tokenized'] = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(train['text']), maxlen=7).tolist()\n",
    "test['text_tokenized'] = tf.keras.preprocessing.sequence.pad_sequences(tokenizer.texts_to_sequences(test['text']), maxlen=7).tolist()\n",
    "train['counts'] = train['meddra_label'].apply(lambda x: train[train['meddra_label']==x].shape[0])\n",
    "#train = train[train['counts']>50]\n",
    "\n",
    "X_train = np.array(train['text_tokenized'].to_list())\n",
    "y_train = np.array(train['meddra_label'].to_list())\n",
    "\n",
    "X_test = np.array(test['text_tokenized'].to_list())\n",
    "y_test = np.array(test['meddra_label'].to_list())\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07a48bbbf9b9475d8e84a4544e5a18a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/150 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tpot = TPOTClassifier(generations=generations, \n",
    "                      population_size=population_size,\n",
    "                      verbosity=2, \n",
    "                      random_state=42, \n",
    "                      max_eval_time_mins=max_eval_time_mins, \n",
    "                      n_jobs=n_jobs)\n",
    "tpot.fit(X_train, y_train)\n",
    "score = tpot.score(X_test, y_test)\n",
    "logging.debug(f'ENRICHED MEDDRA vectorized: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enrich data vec with NCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot = TPOTClassifier(generations=generations, \n",
    "                      population_size=population_size,\n",
    "                      verbosity=2, \n",
    "                      random_state=42, \n",
    "                      max_eval_time_mins=max_eval_time_mins, \n",
    "                      n_jobs=n_jobs)\n",
    "clf = make_pipeline(NCA(max_iter=max_iter), tpot)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "score = tpot.score(X_test, y_test)\n",
    "logging.debug(f'ENRICHED MEDDRA vectorized with NCA: {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
